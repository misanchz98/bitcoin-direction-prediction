{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misanchz98/bitcoin-direction-prediction/blob/main/03_modeling/03_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📊 Modelización con Redes Neuronales"
      ],
      "metadata": {
        "id": "oc3L8941w_7Q"
      },
      "id": "oc3L8941w_7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LIBRERIAS\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Establecer el nivel de advertencias a \"ignore\" para ignorar todas las advertencias\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "PRb5hdMlxdH1"
      },
      "id": "PRb5hdMlxdH1",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resetting the seeds for reproducibility\n",
        "def reset_random_seeds():\n",
        "    n = 1\n",
        "    os.environ['PYTHONHASHSEED'] = str(n)\n",
        "    tf.random.set_seed(n)\n",
        "    np.random.seed(n)\n",
        "    random.seed(n)\n",
        "\n",
        "reset_random_seeds()"
      ],
      "metadata": {
        "id": "AaKg9WJRg45w"
      },
      "id": "AaKg9WJRg45w",
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 1. Importación del conjunto de datos\n",
        "El primer paso consiste en cargar el conjunto de datos en nuestro entorno de trabajo. Estos datos están almacenados en un archivo CSV llamado `btc_historical_data_eda.csv`, cuya creación y obtención se explican en el notebook `02_data_analysis.ipynb`. Para ello, se utiliza el siguiente fragmento de código:"
      ],
      "metadata": {
        "id": "_zZmB5VkxQ8B"
      },
      "id": "_zZmB5VkxQ8B"
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos CSV\n",
        "url = 'https://raw.githubusercontent.com/misanchz98/bitcoin-direction-prediction/main/02_data_analysis/data/btc_historical_data_eda.csv'\n",
        "df_bitcoin = pd.read_csv(url, parse_dates=['Open time'])\n",
        "df_bitcoin"
      ],
      "metadata": {
        "id": "orqWGSQqwZJw",
        "outputId": "e784bd38-1bd2-4657-9281-261c601a45e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        }
      },
      "id": "orqWGSQqwZJw",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Open time      Close  Number of trades  Taker buy base asset volume  \\\n",
              "0    2017-10-05    4292.43            9158.0                   351.042019   \n",
              "1    2017-10-06    4369.00            6546.0                   226.148177   \n",
              "2    2017-10-07    4423.00            4804.0                   145.313076   \n",
              "3    2017-10-08    4640.00            7580.0                   280.094854   \n",
              "4    2017-10-09    4786.95           10372.0                   350.756559   \n",
              "...         ...        ...               ...                          ...   \n",
              "2872 2025-08-16  117380.66         1179842.0                  2995.228650   \n",
              "2873 2025-08-17  117405.01         1177563.0                  2804.731130   \n",
              "2874 2025-08-18  116227.05         3345487.0                  7647.218200   \n",
              "2875 2025-08-19  112872.94         3291170.0                  8609.360780   \n",
              "2876 2025-08-20  114271.24         2998370.0                  7209.585750   \n",
              "\n",
              "      Taker buy quote asset volume    Range   Candle  Target    CMF_20  \\\n",
              "0                     1.483037e+06   245.00    83.84       1  0.081329   \n",
              "1                     9.881066e+05   125.00    50.01       1  0.090972   \n",
              "2                     6.371469e+05   166.94    54.00       1  0.072898   \n",
              "3                     1.268661e+06   233.00   215.00       1  0.064115   \n",
              "4                     1.654275e+06   339.98   146.95       0  0.105281   \n",
              "...                            ...      ...      ...     ...       ...   \n",
              "2872                  3.521588e+08   755.01    38.62       1 -0.078079   \n",
              "2873                  3.307994e+08  1402.79    24.35       0 -0.071478   \n",
              "2874                  8.850528e+08  2903.61 -1177.96       0 -0.058026   \n",
              "2875                  9.840874e+08  3993.11 -3354.11       1 -0.133646   \n",
              "2876                  8.193310e+08  2235.38  1398.29       0 -0.048524   \n",
              "\n",
              "         MFI_14  ...  c2_ta_tendencia  c3_ta_tendencia  c1_ta_momentum  \\\n",
              "0     56.225018  ...         1.426309        -0.136861        1.317719   \n",
              "1     62.048701  ...         1.684975        -0.223654        1.843789   \n",
              "2     60.780168  ...         1.837639        -0.272101        1.714315   \n",
              "3     66.225272  ...         2.655718        -0.595153        4.539268   \n",
              "4     66.423592  ...         3.068594        -0.711866        4.065484   \n",
              "...         ...  ...              ...              ...             ...   \n",
              "2872  61.679789  ...        -2.974279        -0.597347       -1.738575   \n",
              "2873  61.441782  ...        -3.056170        -0.520901       -2.679964   \n",
              "2874  54.527915  ...        -3.371373        -0.335897       -3.708156   \n",
              "2875  53.037041  ...        -4.158761         0.112011       -5.328226   \n",
              "2876  47.355321  ...        -4.010127        -0.035153       -3.323554   \n",
              "\n",
              "      c2_ta_momentum  c3_ta_momentum  c4_ta_momentum  c5_ta_momentum  \\\n",
              "0          -0.126726       -1.676720        1.289633        0.019128   \n",
              "1          -0.313902       -0.766032        1.200655        0.108543   \n",
              "2           0.851111       -1.474281       -0.169404       -0.611932   \n",
              "3          -1.327677       -1.397994        0.344940        0.095779   \n",
              "4           0.284535       -0.496135       -0.373562       -0.383308   \n",
              "...              ...             ...             ...             ...   \n",
              "2872       -0.246759        0.045690        1.947962       -0.826190   \n",
              "2873        0.452454       -1.078307        1.833305       -0.382838   \n",
              "2874        1.216496       -0.767095        1.913662        1.633951   \n",
              "2875        0.713262        0.105456        1.232647       -1.954862   \n",
              "2876       -2.507455       -1.057876        1.180263       -1.303357   \n",
              "\n",
              "      c1_ta_volatilidad  c2_ta_volatilidad  c3_ta_volatilidad  \n",
              "0             -4.644643          -0.938175          -0.259897  \n",
              "1             -4.656021          -1.404483          -0.298095  \n",
              "2             -4.658149          -1.694457          -0.310605  \n",
              "3             -4.643444          -2.930102          -0.299058  \n",
              "4             -4.619178          -3.116037          -0.259659  \n",
              "...                 ...                ...                ...  \n",
              "2872          11.130802           0.715864          -3.617415  \n",
              "2873          11.062656           0.708259          -3.717682  \n",
              "2874          11.085307           1.427748          -3.651715  \n",
              "2875          11.229262           3.161925          -3.269720  \n",
              "2876          11.207456           2.153090          -3.227203  \n",
              "\n",
              "[2877 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58bba706-e3e4-4f54-bf0a-a91565c1f107\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open time</th>\n",
              "      <th>Close</th>\n",
              "      <th>Number of trades</th>\n",
              "      <th>Taker buy base asset volume</th>\n",
              "      <th>Taker buy quote asset volume</th>\n",
              "      <th>Range</th>\n",
              "      <th>Candle</th>\n",
              "      <th>Target</th>\n",
              "      <th>CMF_20</th>\n",
              "      <th>MFI_14</th>\n",
              "      <th>...</th>\n",
              "      <th>c2_ta_tendencia</th>\n",
              "      <th>c3_ta_tendencia</th>\n",
              "      <th>c1_ta_momentum</th>\n",
              "      <th>c2_ta_momentum</th>\n",
              "      <th>c3_ta_momentum</th>\n",
              "      <th>c4_ta_momentum</th>\n",
              "      <th>c5_ta_momentum</th>\n",
              "      <th>c1_ta_volatilidad</th>\n",
              "      <th>c2_ta_volatilidad</th>\n",
              "      <th>c3_ta_volatilidad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-10-05</td>\n",
              "      <td>4292.43</td>\n",
              "      <td>9158.0</td>\n",
              "      <td>351.042019</td>\n",
              "      <td>1.483037e+06</td>\n",
              "      <td>245.00</td>\n",
              "      <td>83.84</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081329</td>\n",
              "      <td>56.225018</td>\n",
              "      <td>...</td>\n",
              "      <td>1.426309</td>\n",
              "      <td>-0.136861</td>\n",
              "      <td>1.317719</td>\n",
              "      <td>-0.126726</td>\n",
              "      <td>-1.676720</td>\n",
              "      <td>1.289633</td>\n",
              "      <td>0.019128</td>\n",
              "      <td>-4.644643</td>\n",
              "      <td>-0.938175</td>\n",
              "      <td>-0.259897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-10-06</td>\n",
              "      <td>4369.00</td>\n",
              "      <td>6546.0</td>\n",
              "      <td>226.148177</td>\n",
              "      <td>9.881066e+05</td>\n",
              "      <td>125.00</td>\n",
              "      <td>50.01</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090972</td>\n",
              "      <td>62.048701</td>\n",
              "      <td>...</td>\n",
              "      <td>1.684975</td>\n",
              "      <td>-0.223654</td>\n",
              "      <td>1.843789</td>\n",
              "      <td>-0.313902</td>\n",
              "      <td>-0.766032</td>\n",
              "      <td>1.200655</td>\n",
              "      <td>0.108543</td>\n",
              "      <td>-4.656021</td>\n",
              "      <td>-1.404483</td>\n",
              "      <td>-0.298095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-10-07</td>\n",
              "      <td>4423.00</td>\n",
              "      <td>4804.0</td>\n",
              "      <td>145.313076</td>\n",
              "      <td>6.371469e+05</td>\n",
              "      <td>166.94</td>\n",
              "      <td>54.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.072898</td>\n",
              "      <td>60.780168</td>\n",
              "      <td>...</td>\n",
              "      <td>1.837639</td>\n",
              "      <td>-0.272101</td>\n",
              "      <td>1.714315</td>\n",
              "      <td>0.851111</td>\n",
              "      <td>-1.474281</td>\n",
              "      <td>-0.169404</td>\n",
              "      <td>-0.611932</td>\n",
              "      <td>-4.658149</td>\n",
              "      <td>-1.694457</td>\n",
              "      <td>-0.310605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-10-08</td>\n",
              "      <td>4640.00</td>\n",
              "      <td>7580.0</td>\n",
              "      <td>280.094854</td>\n",
              "      <td>1.268661e+06</td>\n",
              "      <td>233.00</td>\n",
              "      <td>215.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.064115</td>\n",
              "      <td>66.225272</td>\n",
              "      <td>...</td>\n",
              "      <td>2.655718</td>\n",
              "      <td>-0.595153</td>\n",
              "      <td>4.539268</td>\n",
              "      <td>-1.327677</td>\n",
              "      <td>-1.397994</td>\n",
              "      <td>0.344940</td>\n",
              "      <td>0.095779</td>\n",
              "      <td>-4.643444</td>\n",
              "      <td>-2.930102</td>\n",
              "      <td>-0.299058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-10-09</td>\n",
              "      <td>4786.95</td>\n",
              "      <td>10372.0</td>\n",
              "      <td>350.756559</td>\n",
              "      <td>1.654275e+06</td>\n",
              "      <td>339.98</td>\n",
              "      <td>146.95</td>\n",
              "      <td>0</td>\n",
              "      <td>0.105281</td>\n",
              "      <td>66.423592</td>\n",
              "      <td>...</td>\n",
              "      <td>3.068594</td>\n",
              "      <td>-0.711866</td>\n",
              "      <td>4.065484</td>\n",
              "      <td>0.284535</td>\n",
              "      <td>-0.496135</td>\n",
              "      <td>-0.373562</td>\n",
              "      <td>-0.383308</td>\n",
              "      <td>-4.619178</td>\n",
              "      <td>-3.116037</td>\n",
              "      <td>-0.259659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2872</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>117380.66</td>\n",
              "      <td>1179842.0</td>\n",
              "      <td>2995.228650</td>\n",
              "      <td>3.521588e+08</td>\n",
              "      <td>755.01</td>\n",
              "      <td>38.62</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.078079</td>\n",
              "      <td>61.679789</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.974279</td>\n",
              "      <td>-0.597347</td>\n",
              "      <td>-1.738575</td>\n",
              "      <td>-0.246759</td>\n",
              "      <td>0.045690</td>\n",
              "      <td>1.947962</td>\n",
              "      <td>-0.826190</td>\n",
              "      <td>11.130802</td>\n",
              "      <td>0.715864</td>\n",
              "      <td>-3.617415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2873</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>117405.01</td>\n",
              "      <td>1177563.0</td>\n",
              "      <td>2804.731130</td>\n",
              "      <td>3.307994e+08</td>\n",
              "      <td>1402.79</td>\n",
              "      <td>24.35</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.071478</td>\n",
              "      <td>61.441782</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.056170</td>\n",
              "      <td>-0.520901</td>\n",
              "      <td>-2.679964</td>\n",
              "      <td>0.452454</td>\n",
              "      <td>-1.078307</td>\n",
              "      <td>1.833305</td>\n",
              "      <td>-0.382838</td>\n",
              "      <td>11.062656</td>\n",
              "      <td>0.708259</td>\n",
              "      <td>-3.717682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2874</th>\n",
              "      <td>2025-08-18</td>\n",
              "      <td>116227.05</td>\n",
              "      <td>3345487.0</td>\n",
              "      <td>7647.218200</td>\n",
              "      <td>8.850528e+08</td>\n",
              "      <td>2903.61</td>\n",
              "      <td>-1177.96</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.058026</td>\n",
              "      <td>54.527915</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.371373</td>\n",
              "      <td>-0.335897</td>\n",
              "      <td>-3.708156</td>\n",
              "      <td>1.216496</td>\n",
              "      <td>-0.767095</td>\n",
              "      <td>1.913662</td>\n",
              "      <td>1.633951</td>\n",
              "      <td>11.085307</td>\n",
              "      <td>1.427748</td>\n",
              "      <td>-3.651715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2875</th>\n",
              "      <td>2025-08-19</td>\n",
              "      <td>112872.94</td>\n",
              "      <td>3291170.0</td>\n",
              "      <td>8609.360780</td>\n",
              "      <td>9.840874e+08</td>\n",
              "      <td>3993.11</td>\n",
              "      <td>-3354.11</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.133646</td>\n",
              "      <td>53.037041</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.158761</td>\n",
              "      <td>0.112011</td>\n",
              "      <td>-5.328226</td>\n",
              "      <td>0.713262</td>\n",
              "      <td>0.105456</td>\n",
              "      <td>1.232647</td>\n",
              "      <td>-1.954862</td>\n",
              "      <td>11.229262</td>\n",
              "      <td>3.161925</td>\n",
              "      <td>-3.269720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>2025-08-20</td>\n",
              "      <td>114271.24</td>\n",
              "      <td>2998370.0</td>\n",
              "      <td>7209.585750</td>\n",
              "      <td>8.193310e+08</td>\n",
              "      <td>2235.38</td>\n",
              "      <td>1398.29</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.048524</td>\n",
              "      <td>47.355321</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.010127</td>\n",
              "      <td>-0.035153</td>\n",
              "      <td>-3.323554</td>\n",
              "      <td>-2.507455</td>\n",
              "      <td>-1.057876</td>\n",
              "      <td>1.180263</td>\n",
              "      <td>-1.303357</td>\n",
              "      <td>11.207456</td>\n",
              "      <td>2.153090</td>\n",
              "      <td>-3.227203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2877 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58bba706-e3e4-4f54-bf0a-a91565c1f107')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58bba706-e3e4-4f54-bf0a-a91565c1f107 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58bba706-e3e4-4f54-bf0a-a91565c1f107');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3d79f0cd-c11e-440d-8e95-af216bd3fb6a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d79f0cd-c11e-440d-8e95-af216bd3fb6a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3d79f0cd-c11e-440d-8e95-af216bd3fb6a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9a0e8658-bbee-4abf-9b91-e5372477c2fe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_bitcoin')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9a0e8658-bbee-4abf-9b91-e5372477c2fe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_bitcoin');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_bitcoin"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 2. División del conjunto de datos"
      ],
      "metadata": {
        "id": "gpxUhj2LfI3z"
      },
      "id": "gpxUhj2LfI3z"
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_bitcoin.drop(['Open time', 'Target'], axis=1)\n",
        "y = df_bitcoin['Target']\n",
        "\n",
        "# separate training data from testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# scale the input data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Reshape X_train and X_test if they are 1D\n",
        "if X_train.ndim == 1:\n",
        "    X_train = X_train.to_numpy().reshape(-1, 1)\n",
        "if X_test.ndim == 1:\n",
        "    X_test = X_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# reshape the input data for CNN-LSTM (samples, timesteps, features)\n",
        "def create_sequences(data, timesteps):\n",
        "    X = []\n",
        "    for i in range(len(data) - timesteps + 1):\n",
        "        X.append(data[i:i + timesteps])\n",
        "    return np.array(X)\n",
        "\n",
        "timesteps = 14\n",
        "X_train_reshaped = create_sequences(X_train_scaled, timesteps)\n",
        "X_test_reshaped = create_sequences(X_test_scaled, timesteps)\n",
        "y_train = y_train[timesteps - 1:]\n",
        "y_test = y_test[timesteps - 1:]"
      ],
      "metadata": {
        "id": "rtEjAgeufewH"
      },
      "id": "rtEjAgeufewH",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "ENlCQ09tmahV"
      },
      "id": "ENlCQ09tmahV"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1_score_2(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "_rBNXkQCsz8S"
      },
      "id": "_rBNXkQCsz8S",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # binaria\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[metrics.BinaryAccuracy(), metrics.Precision(), metrics.Recall(), f1_score_2]\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_binary_accuracy',  # mejor usar val_binary_accuracy\n",
        "    patience=50,\n",
        "    mode='max',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train.astype('float32'),  # convertir a float32\n",
        "    epochs=100,\n",
        "    batch_size=50,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "id": "jheEAEKQs72Y",
        "outputId": "c9fdaa0a-4bb6-49fb-c766-34c702ae6718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jheEAEKQs72Y",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - binary_accuracy: 0.5096 - f1_score_2: 0.5394 - loss: 0.6999 - precision_7: 0.5254 - recall_7: 0.5743 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.6479 - val_loss: 0.6908 - val_precision_7: 0.5260 - val_recall_7: 0.8707\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.4901 - f1_score_2: 0.5586 - loss: 0.6992 - precision_7: 0.5072 - recall_7: 0.6355 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.5544 - val_loss: 0.6933 - val_precision_7: 0.5298 - val_recall_7: 0.6897\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5085 - f1_score_2: 0.5647 - loss: 0.6928 - precision_7: 0.5217 - recall_7: 0.6372 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.6518 - val_loss: 0.6952 - val_precision_7: 0.5226 - val_recall_7: 0.8966\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5099 - f1_score_2: 0.5592 - loss: 0.6930 - precision_7: 0.5236 - recall_7: 0.6242 - val_binary_accuracy: 0.5197 - val_f1_score_2: 0.6656 - val_loss: 0.6963 - val_precision_7: 0.5138 - val_recall_7: 0.9655\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5396 - f1_score_2: 0.5776 - loss: 0.6892 - precision_7: 0.5484 - recall_7: 0.6308 - val_binary_accuracy: 0.5066 - val_f1_score_2: 0.6687 - val_loss: 0.7062 - val_precision_7: 0.5066 - val_recall_7: 1.0000\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 0.5415 - f1_score_2: 0.5906 - loss: 0.6881 - precision_7: 0.5476 - recall_7: 0.6701 - val_binary_accuracy: 0.5066 - val_f1_score_2: 0.6687 - val_loss: 0.7113 - val_precision_7: 0.5066 - val_recall_7: 1.0000\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5451 - f1_score_2: 0.6054 - loss: 0.6876 - precision_7: 0.5481 - recall_7: 0.7090 - val_binary_accuracy: 0.5066 - val_f1_score_2: 0.6687 - val_loss: 0.7166 - val_precision_7: 0.5066 - val_recall_7: 1.0000\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5484 - f1_score_2: 0.6049 - loss: 0.6873 - precision_7: 0.5517 - recall_7: 0.6936 - val_binary_accuracy: 0.5066 - val_f1_score_2: 0.6687 - val_loss: 0.7157 - val_precision_7: 0.5066 - val_recall_7: 1.0000\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5314 - f1_score_2: 0.5844 - loss: 0.6922 - precision_7: 0.5437 - recall_7: 0.6532 - val_binary_accuracy: 0.5109 - val_f1_score_2: 0.6652 - val_loss: 0.7066 - val_precision_7: 0.5090 - val_recall_7: 0.9741\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5485 - f1_score_2: 0.6079 - loss: 0.6861 - precision_7: 0.5522 - recall_7: 0.6914 - val_binary_accuracy: 0.5022 - val_f1_score_2: 0.5720 - val_loss: 0.7038 - val_precision_7: 0.5058 - val_recall_7: 0.7500\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5781 - f1_score_2: 0.6265 - loss: 0.6792 - precision_7: 0.5769 - recall_7: 0.7032 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.6717 - val_loss: 0.6991 - val_precision_7: 0.5236 - val_recall_7: 0.9569\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5682 - f1_score_2: 0.6048 - loss: 0.6741 - precision_7: 0.5742 - recall_7: 0.6537 - val_binary_accuracy: 0.5022 - val_f1_score_2: 0.6396 - val_loss: 0.7234 - val_precision_7: 0.5049 - val_recall_7: 0.8879\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5808 - f1_score_2: 0.6196 - loss: 0.6756 - precision_7: 0.5855 - recall_7: 0.6659 - val_binary_accuracy: 0.5197 - val_f1_score_2: 0.6665 - val_loss: 0.7244 - val_precision_7: 0.5138 - val_recall_7: 0.9655\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5994 - f1_score_2: 0.6267 - loss: 0.6656 - precision_7: 0.6037 - recall_7: 0.6637 - val_binary_accuracy: 0.5153 - val_f1_score_2: 0.6335 - val_loss: 0.7285 - val_precision_7: 0.5128 - val_recall_7: 0.8621\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5945 - f1_score_2: 0.6065 - loss: 0.6678 - precision_7: 0.6080 - recall_7: 0.6165 - val_binary_accuracy: 0.4847 - val_f1_score_2: 0.6249 - val_loss: 0.7748 - val_precision_7: 0.4950 - val_recall_7: 0.8621\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5995 - f1_score_2: 0.6128 - loss: 0.6651 - precision_7: 0.6118 - recall_7: 0.6303 - val_binary_accuracy: 0.5022 - val_f1_score_2: 0.5830 - val_loss: 0.7279 - val_precision_7: 0.5061 - val_recall_7: 0.7155\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.5970 - f1_score_2: 0.6282 - loss: 0.6609 - precision_7: 0.6020 - recall_7: 0.6641 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.5457 - val_loss: 0.7433 - val_precision_7: 0.5290 - val_recall_7: 0.6293\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6058 - f1_score_2: 0.6294 - loss: 0.6528 - precision_7: 0.6139 - recall_7: 0.6534 - val_binary_accuracy: 0.4847 - val_f1_score_2: 0.6152 - val_loss: 0.7361 - val_precision_7: 0.4949 - val_recall_7: 0.8362\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6186 - f1_score_2: 0.6458 - loss: 0.6420 - precision_7: 0.6198 - recall_7: 0.6836 - val_binary_accuracy: 0.5066 - val_f1_score_2: 0.6173 - val_loss: 0.7189 - val_precision_7: 0.5081 - val_recall_7: 0.8103\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6416 - f1_score_2: 0.6719 - loss: 0.6242 - precision_7: 0.6363 - recall_7: 0.7211 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.5659 - val_loss: 0.7391 - val_precision_7: 0.5306 - val_recall_7: 0.6724\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6360 - f1_score_2: 0.6534 - loss: 0.6176 - precision_7: 0.6455 - recall_7: 0.6686 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.6345 - val_loss: 0.7202 - val_precision_7: 0.5217 - val_recall_7: 0.8276\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6759 - f1_score_2: 0.6887 - loss: 0.6071 - precision_7: 0.6843 - recall_7: 0.6982 - val_binary_accuracy: 0.4891 - val_f1_score_2: 0.4990 - val_loss: 0.7432 - val_precision_7: 0.4957 - val_recall_7: 0.5000\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6629 - f1_score_2: 0.6881 - loss: 0.5992 - precision_7: 0.6610 - recall_7: 0.7223 - val_binary_accuracy: 0.5502 - val_f1_score_2: 0.6297 - val_loss: 0.7220 - val_precision_7: 0.5380 - val_recall_7: 0.7931\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6841 - f1_score_2: 0.6994 - loss: 0.5780 - precision_7: 0.6876 - recall_7: 0.7171 - val_binary_accuracy: 0.5153 - val_f1_score_2: 0.5735 - val_loss: 0.7577 - val_precision_7: 0.5157 - val_recall_7: 0.7069\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6891 - f1_score_2: 0.7021 - loss: 0.5782 - precision_7: 0.6958 - recall_7: 0.7138 - val_binary_accuracy: 0.5459 - val_f1_score_2: 0.6757 - val_loss: 0.7370 - val_precision_7: 0.5286 - val_recall_7: 0.9569\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6993 - f1_score_2: 0.7069 - loss: 0.5642 - precision_7: 0.7086 - recall_7: 0.7153 - val_binary_accuracy: 0.5633 - val_f1_score_2: 0.5996 - val_loss: 0.7396 - val_precision_7: 0.5563 - val_recall_7: 0.6810\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6991 - f1_score_2: 0.7088 - loss: 0.5502 - precision_7: 0.7054 - recall_7: 0.7224 - val_binary_accuracy: 0.5459 - val_f1_score_2: 0.5720 - val_loss: 0.7142 - val_precision_7: 0.5455 - val_recall_7: 0.6207\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7277 - f1_score_2: 0.7348 - loss: 0.5216 - precision_7: 0.7333 - recall_7: 0.7478 - val_binary_accuracy: 0.5590 - val_f1_score_2: 0.6251 - val_loss: 0.7376 - val_precision_7: 0.5466 - val_recall_7: 0.7586\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7518 - f1_score_2: 0.7578 - loss: 0.4868 - precision_7: 0.7625 - recall_7: 0.7598 - val_binary_accuracy: 0.5633 - val_f1_score_2: 0.5308 - val_loss: 0.8823 - val_precision_7: 0.5784 - val_recall_7: 0.5086\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7809 - f1_score_2: 0.7865 - loss: 0.4543 - precision_7: 0.7859 - recall_7: 0.7946 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.5045 - val_loss: 0.8552 - val_precision_7: 0.5377 - val_recall_7: 0.4914\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 0.7797 - f1_score_2: 0.7827 - loss: 0.4529 - precision_7: 0.7936 - recall_7: 0.7782 - val_binary_accuracy: 0.5415 - val_f1_score_2: 0.5483 - val_loss: 0.8734 - val_precision_7: 0.5440 - val_recall_7: 0.5862\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8171 - f1_score_2: 0.8207 - loss: 0.4037 - precision_7: 0.8205 - recall_7: 0.8302 - val_binary_accuracy: 0.5459 - val_f1_score_2: 0.5242 - val_loss: 1.0655 - val_precision_7: 0.5556 - val_recall_7: 0.5172\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8219 - f1_score_2: 0.8246 - loss: 0.3822 - precision_7: 0.8243 - recall_7: 0.8351 - val_binary_accuracy: 0.5590 - val_f1_score_2: 0.4584 - val_loss: 0.9891 - val_precision_7: 0.6000 - val_recall_7: 0.3879\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8417 - f1_score_2: 0.8458 - loss: 0.3701 - precision_7: 0.8477 - recall_7: 0.8475 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4718 - val_loss: 1.0670 - val_precision_7: 0.5543 - val_recall_7: 0.4397\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8386 - f1_score_2: 0.8414 - loss: 0.3421 - precision_7: 0.8486 - recall_7: 0.8392 - val_binary_accuracy: 0.5502 - val_f1_score_2: 0.4774 - val_loss: 1.2653 - val_precision_7: 0.5730 - val_recall_7: 0.4397\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8591 - f1_score_2: 0.8609 - loss: 0.3135 - precision_7: 0.8660 - recall_7: 0.8617 - val_binary_accuracy: 0.5895 - val_f1_score_2: 0.5621 - val_loss: 1.2084 - val_precision_7: 0.5982 - val_recall_7: 0.5776\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8809 - f1_score_2: 0.8826 - loss: 0.3000 - precision_7: 0.8781 - recall_7: 0.8943 - val_binary_accuracy: 0.5590 - val_f1_score_2: 0.4603 - val_loss: 1.2629 - val_precision_7: 0.5882 - val_recall_7: 0.4310\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8686 - f1_score_2: 0.8704 - loss: 0.2969 - precision_7: 0.8813 - recall_7: 0.8628 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.4207 - val_loss: 1.3656 - val_precision_7: 0.5500 - val_recall_7: 0.3793\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8535 - f1_score_2: 0.8557 - loss: 0.3190 - precision_7: 0.8624 - recall_7: 0.8543 - val_binary_accuracy: 0.5590 - val_f1_score_2: 0.4759 - val_loss: 1.5323 - val_precision_7: 0.5882 - val_recall_7: 0.4310\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8855 - f1_score_2: 0.8883 - loss: 0.2575 - precision_7: 0.8899 - recall_7: 0.8895 - val_binary_accuracy: 0.5633 - val_f1_score_2: 0.4933 - val_loss: 1.5119 - val_precision_7: 0.5870 - val_recall_7: 0.4655\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8979 - f1_score_2: 0.9008 - loss: 0.2561 - precision_7: 0.8939 - recall_7: 0.9109 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.3627 - val_loss: 1.6274 - val_precision_7: 0.5818 - val_recall_7: 0.2759\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9032 - f1_score_2: 0.9065 - loss: 0.2184 - precision_7: 0.8950 - recall_7: 0.9221 - val_binary_accuracy: 0.5459 - val_f1_score_2: 0.3952 - val_loss: 1.5591 - val_precision_7: 0.5909 - val_recall_7: 0.3362\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9348 - f1_score_2: 0.9340 - loss: 0.1796 - precision_7: 0.9304 - recall_7: 0.9446 - val_binary_accuracy: 0.5240 - val_f1_score_2: 0.3727 - val_loss: 1.7343 - val_precision_7: 0.5507 - val_recall_7: 0.3276\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9069 - f1_score_2: 0.9112 - loss: 0.2031 - precision_7: 0.8974 - recall_7: 0.9268 - val_binary_accuracy: 0.4891 - val_f1_score_2: 0.3684 - val_loss: 1.8660 - val_precision_7: 0.4937 - val_recall_7: 0.3362\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9402 - f1_score_2: 0.9409 - loss: 0.1521 - precision_7: 0.9357 - recall_7: 0.9502 - val_binary_accuracy: 0.5590 - val_f1_score_2: 0.4606 - val_loss: 2.0173 - val_precision_7: 0.5974 - val_recall_7: 0.3966\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9401 - f1_score_2: 0.9418 - loss: 0.1634 - precision_7: 0.9424 - recall_7: 0.9423 - val_binary_accuracy: 0.5546 - val_f1_score_2: 0.3877 - val_loss: 1.8821 - val_precision_7: 0.6207 - val_recall_7: 0.3103\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9495 - f1_score_2: 0.9480 - loss: 0.1389 - precision_7: 0.9589 - recall_7: 0.9438 - val_binary_accuracy: 0.5590 - val_f1_score_2: 0.3760 - val_loss: 2.0167 - val_precision_7: 0.6364 - val_recall_7: 0.3017\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9581 - f1_score_2: 0.9600 - loss: 0.1182 - precision_7: 0.9698 - recall_7: 0.9490 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.3628 - val_loss: 2.0707 - val_precision_7: 0.5625 - val_recall_7: 0.3103\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9581 - f1_score_2: 0.9575 - loss: 0.1301 - precision_7: 0.9669 - recall_7: 0.9518 - val_binary_accuracy: 0.5415 - val_f1_score_2: 0.3703 - val_loss: 2.0006 - val_precision_7: 0.5932 - val_recall_7: 0.3017\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9500 - f1_score_2: 0.9508 - loss: 0.1282 - precision_7: 0.9608 - recall_7: 0.9422 - val_binary_accuracy: 0.5502 - val_f1_score_2: 0.3964 - val_loss: 1.8144 - val_precision_7: 0.6032 - val_recall_7: 0.3276\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9602 - f1_score_2: 0.9602 - loss: 0.1176 - precision_7: 0.9696 - recall_7: 0.9533 - val_binary_accuracy: 0.5197 - val_f1_score_2: 0.3803 - val_loss: 2.1021 - val_precision_7: 0.5441 - val_recall_7: 0.3190\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 0.9686 - f1_score_2: 0.9698 - loss: 0.0948 - precision_7: 0.9747 - recall_7: 0.9646 - val_binary_accuracy: 0.5546 - val_f1_score_2: 0.5303 - val_loss: 1.8867 - val_precision_7: 0.5636 - val_recall_7: 0.5345\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9656 - f1_score_2: 0.9673 - loss: 0.0944 - precision_7: 0.9678 - recall_7: 0.9659 - val_binary_accuracy: 0.4978 - val_f1_score_2: 0.3929 - val_loss: 1.9800 - val_precision_7: 0.5062 - val_recall_7: 0.3534\n",
            "Epoch 54/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 0.9708 - f1_score_2: 0.9708 - loss: 0.0821 - precision_7: 0.9749 - recall_7: 0.9686 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.4690 - val_loss: 2.0789 - val_precision_7: 0.5495 - val_recall_7: 0.4310\n",
            "Epoch 55/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9701 - f1_score_2: 0.9707 - loss: 0.0871 - precision_7: 0.9760 - recall_7: 0.9663 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.4695 - val_loss: 2.0615 - val_precision_7: 0.5408 - val_recall_7: 0.4569\n",
            "Epoch 56/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9795 - f1_score_2: 0.9807 - loss: 0.0618 - precision_7: 0.9815 - recall_7: 0.9790 - val_binary_accuracy: 0.5459 - val_f1_score_2: 0.4753 - val_loss: 2.2277 - val_precision_7: 0.5638 - val_recall_7: 0.4569\n",
            "Epoch 57/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9725 - f1_score_2: 0.9740 - loss: 0.0765 - precision_7: 0.9751 - recall_7: 0.9721 - val_binary_accuracy: 0.5415 - val_f1_score_2: 0.4884 - val_loss: 2.1307 - val_precision_7: 0.5534 - val_recall_7: 0.4914\n",
            "Epoch 58/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9873 - f1_score_2: 0.9877 - loss: 0.0412 - precision_7: 0.9898 - recall_7: 0.9857 - val_binary_accuracy: 0.5633 - val_f1_score_2: 0.5243 - val_loss: 2.1739 - val_precision_7: 0.5784 - val_recall_7: 0.5086\n",
            "Epoch 59/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9720 - f1_score_2: 0.9723 - loss: 0.0822 - precision_7: 0.9703 - recall_7: 0.9760 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.4810 - val_loss: 2.0990 - val_precision_7: 0.5437 - val_recall_7: 0.4828\n",
            "Epoch 60/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9826 - f1_score_2: 0.9821 - loss: 0.0583 - precision_7: 0.9783 - recall_7: 0.9882 - val_binary_accuracy: 0.5459 - val_f1_score_2: 0.5049 - val_loss: 2.0887 - val_precision_7: 0.5600 - val_recall_7: 0.4828\n",
            "Epoch 61/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9871 - f1_score_2: 0.9876 - loss: 0.0376 - precision_7: 0.9880 - recall_7: 0.9871 - val_binary_accuracy: 0.5197 - val_f1_score_2: 0.4529 - val_loss: 2.3880 - val_precision_7: 0.5306 - val_recall_7: 0.4483\n",
            "Epoch 62/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9884 - f1_score_2: 0.9884 - loss: 0.0384 - precision_7: 0.9872 - recall_7: 0.9905 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.4708 - val_loss: 2.5318 - val_precision_7: 0.5392 - val_recall_7: 0.4741\n",
            "Epoch 63/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9905 - f1_score_2: 0.9905 - loss: 0.0423 - precision_7: 0.9881 - recall_7: 0.9937 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4767 - val_loss: 2.3978 - val_precision_7: 0.5510 - val_recall_7: 0.4655\n",
            "Epoch 64/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9888 - f1_score_2: 0.9886 - loss: 0.0435 - precision_7: 0.9873 - recall_7: 0.9910 - val_binary_accuracy: 0.5109 - val_f1_score_2: 0.4622 - val_loss: 2.5862 - val_precision_7: 0.5192 - val_recall_7: 0.4655\n",
            "Epoch 65/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9819 - f1_score_2: 0.9821 - loss: 0.0547 - precision_7: 0.9780 - recall_7: 0.9875 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.4509 - val_loss: 2.5304 - val_precision_7: 0.5484 - val_recall_7: 0.4397\n",
            "Epoch 66/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9865 - f1_score_2: 0.9860 - loss: 0.0492 - precision_7: 0.9875 - recall_7: 0.9865 - val_binary_accuracy: 0.5240 - val_f1_score_2: 0.4524 - val_loss: 2.5866 - val_precision_7: 0.5376 - val_recall_7: 0.4310\n",
            "Epoch 67/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9843 - f1_score_2: 0.9850 - loss: 0.0520 - precision_7: 0.9835 - recall_7: 0.9864 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.4698 - val_loss: 2.4849 - val_precision_7: 0.5392 - val_recall_7: 0.4741\n",
            "Epoch 68/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9883 - f1_score_2: 0.9881 - loss: 0.0378 - precision_7: 0.9898 - recall_7: 0.9877 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4439 - val_loss: 2.4727 - val_precision_7: 0.5595 - val_recall_7: 0.4052\n",
            "Epoch 69/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9871 - f1_score_2: 0.9868 - loss: 0.0445 - precision_7: 0.9924 - recall_7: 0.9825 - val_binary_accuracy: 0.5153 - val_f1_score_2: 0.4260 - val_loss: 2.3723 - val_precision_7: 0.5294 - val_recall_7: 0.3879\n",
            "Epoch 70/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9922 - f1_score_2: 0.9928 - loss: 0.0379 - precision_7: 0.9933 - recall_7: 0.9918 - val_binary_accuracy: 0.5066 - val_f1_score_2: 0.3947 - val_loss: 2.6229 - val_precision_7: 0.5195 - val_recall_7: 0.3448\n",
            "Epoch 71/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9862 - f1_score_2: 0.9858 - loss: 0.0489 - precision_7: 0.9887 - recall_7: 0.9848 - val_binary_accuracy: 0.5240 - val_f1_score_2: 0.4445 - val_loss: 2.4124 - val_precision_7: 0.5412 - val_recall_7: 0.3966\n",
            "Epoch 72/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9785 - f1_score_2: 0.9775 - loss: 0.0646 - precision_7: 0.9839 - recall_7: 0.9744 - val_binary_accuracy: 0.5240 - val_f1_score_2: 0.4636 - val_loss: 2.3082 - val_precision_7: 0.5376 - val_recall_7: 0.4310\n",
            "Epoch 73/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9915 - f1_score_2: 0.9915 - loss: 0.0295 - precision_7: 0.9937 - recall_7: 0.9900 - val_binary_accuracy: 0.5284 - val_f1_score_2: 0.4686 - val_loss: 2.5839 - val_precision_7: 0.5426 - val_recall_7: 0.4397\n",
            "Epoch 74/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9862 - f1_score_2: 0.9867 - loss: 0.0425 - precision_7: 0.9809 - recall_7: 0.9928 - val_binary_accuracy: 0.5109 - val_f1_score_2: 0.4413 - val_loss: 2.5726 - val_precision_7: 0.5213 - val_recall_7: 0.4224\n",
            "Epoch 75/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 0.9953 - f1_score_2: 0.9952 - loss: 0.0191 - precision_7: 0.9932 - recall_7: 0.9979 - val_binary_accuracy: 0.4978 - val_f1_score_2: 0.4217 - val_loss: 2.9892 - val_precision_7: 0.5053 - val_recall_7: 0.4138\n",
            "Epoch 76/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9867 - f1_score_2: 0.9865 - loss: 0.0384 - precision_7: 0.9880 - recall_7: 0.9865 - val_binary_accuracy: 0.5109 - val_f1_score_2: 0.4623 - val_loss: 2.6850 - val_precision_7: 0.5200 - val_recall_7: 0.4483\n",
            "Epoch 77/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 0.9817 - f1_score_2: 0.9822 - loss: 0.0447 - precision_7: 0.9783 - recall_7: 0.9868 - val_binary_accuracy: 0.5415 - val_f1_score_2: 0.4743 - val_loss: 2.6841 - val_precision_7: 0.5618 - val_recall_7: 0.4310\n",
            "Epoch 78/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9869 - f1_score_2: 0.9867 - loss: 0.0446 - precision_7: 0.9858 - recall_7: 0.9891 - val_binary_accuracy: 0.5502 - val_f1_score_2: 0.5056 - val_loss: 2.0975 - val_precision_7: 0.5657 - val_recall_7: 0.4828\n",
            "Epoch 79/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9769 - f1_score_2: 0.9774 - loss: 0.0744 - precision_7: 0.9740 - recall_7: 0.9820 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4463 - val_loss: 2.1366 - val_precision_7: 0.5625 - val_recall_7: 0.3879\n",
            "Epoch 80/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9824 - f1_score_2: 0.9841 - loss: 0.0510 - precision_7: 0.9779 - recall_7: 0.9887 - val_binary_accuracy: 0.5633 - val_f1_score_2: 0.4850 - val_loss: 1.8559 - val_precision_7: 0.5976 - val_recall_7: 0.4224\n",
            "Epoch 81/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9810 - f1_score_2: 0.9805 - loss: 0.0687 - precision_7: 0.9858 - recall_7: 0.9774 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4369 - val_loss: 1.9673 - val_precision_7: 0.5610 - val_recall_7: 0.3966\n",
            "Epoch 82/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9941 - f1_score_2: 0.9942 - loss: 0.0227 - precision_7: 0.9940 - recall_7: 0.9944 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4799 - val_loss: 2.2055 - val_precision_7: 0.5500 - val_recall_7: 0.4741\n",
            "Epoch 83/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9950 - f1_score_2: 0.9948 - loss: 0.0169 - precision_7: 0.9932 - recall_7: 0.9973 - val_binary_accuracy: 0.5546 - val_f1_score_2: 0.4991 - val_loss: 2.4123 - val_precision_7: 0.5700 - val_recall_7: 0.4914\n",
            "Epoch 84/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9934 - f1_score_2: 0.9939 - loss: 0.0306 - precision_7: 0.9904 - recall_7: 0.9970 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4548 - val_loss: 2.3468 - val_precision_7: 0.5556 - val_recall_7: 0.4310\n",
            "Epoch 85/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 0.9902 - f1_score_2: 0.9905 - loss: 0.0335 - precision_7: 0.9904 - recall_7: 0.9907 - val_binary_accuracy: 0.5328 - val_f1_score_2: 0.4184 - val_loss: 2.4075 - val_precision_7: 0.5570 - val_recall_7: 0.3793\n",
            "Epoch 86/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9884 - f1_score_2: 0.9887 - loss: 0.0387 - precision_7: 0.9810 - recall_7: 0.9970 - val_binary_accuracy: 0.5371 - val_f1_score_2: 0.4494 - val_loss: 2.4738 - val_precision_7: 0.5568 - val_recall_7: 0.4224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# evaluate the prediction performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "3iamdVWptEOx",
        "outputId": "c36ed4fb-70d8-408f-b163-9d2d38a9fcb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3iamdVWptEOx",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "Accuracy: 0.5257548845470693\n",
            "Precision: 0.5755813953488372\n",
            "Recall: 0.3378839590443686\n",
            "F1-score: 0.4258064516129032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Walk-Forward en df_bitcoin\n",
        "# =========================================\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.keras import Sequential\n",
        "#from tensorflow.keras.layers import LSTM, GRU, Dense, Conv1D, MaxPooling1D, Dropout\n",
        "#from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "#from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "#from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "#\n",
        "## -----------------------------\n",
        "## Funciones de ventanas (las tuyas)\n",
        "## -----------------------------\n",
        "#def create_windows_multivariate_np(data, window_size, horizon, target_col_idx, shuffle=False):\n",
        "#    if isinstance(data, pd.DataFrame):\n",
        "#        data = data.values\n",
        "#    X, y = [], []\n",
        "#    for i in range(len(data) - window_size - horizon + 1):\n",
        "#        X.append(data[i:i+window_size, :])\n",
        "#        y.append(data[i+window_size+horizon-1, target_col_idx])\n",
        "#    X, y = np.array(X), np.array(y)\n",
        "#    if shuffle:\n",
        "#        indices = np.arange(X.shape[0])\n",
        "#        np.random.shuffle(indices)\n",
        "#        X, y = X[indices], y[indices]\n",
        "#    return X, y\n",
        "#\n",
        "## -----------------------------\n",
        "## Builders de modelos\n",
        "## -----------------------------\n",
        "#def build_lstm(input_shape):\n",
        "#    model = Sequential([\n",
        "#        LSTM(64, input_shape=input_shape),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_gru(input_shape):\n",
        "#    model = Sequential([\n",
        "#        GRU(64, input_shape=input_shape),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_lstm(input_shape):\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        LSTM(64),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_gru(input_shape):\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        GRU(64),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#MODEL_BUILDERS = {\n",
        "#    \"LSTM\": build_lstm,\n",
        "#    \"GRU\": build_gru,\n",
        "#    \"CNN+LSTM\": build_cnn_lstm,\n",
        "#    \"CNN+GRU\": build_cnn_gru\n",
        "#}\n",
        "#\n",
        "## 1. BUILDERS DE MODELOS MEJORADOS\n",
        "#def build_lstm_improved(input_shape):\n",
        "#    \"\"\"LSTM mejorado con mejor arquitectura\"\"\"\n",
        "#    model = Sequential([\n",
        "#        LSTM(128, return_sequences=True, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        LSTM(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_gru_improved(input_shape):\n",
        "#    \"\"\"GRU mejorado con regularización\"\"\"\n",
        "#    model = Sequential([\n",
        "#        GRU(128, return_sequences=True, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        GRU(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_lstm_improved(input_shape):\n",
        "#    \"\"\"CNN+LSTM mejorado con múltiples escalas\"\"\"\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=input_shape),\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        Dropout(0.2),\n",
        "#        LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        LSTM(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_gru_improved(input_shape):\n",
        "#    \"\"\"CNN+GRU mejorado\"\"\"\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=input_shape),\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        Dropout(0.2),\n",
        "#        GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        GRU(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "## Diccionario de modelos\n",
        "#MODEL_BUILDERS_IMPROVED = {\n",
        "#    \"LSTM\": build_lstm_improved,\n",
        "#    \"GRU\": build_gru_improved,\n",
        "#    \"CNN+LSTM\": build_cnn_lstm_improved,\n",
        "#    \"CNN+GRU\": build_cnn_gru_improved\n",
        "#}\n",
        "#\n",
        "#\n",
        "## -----------------------------\n",
        "## Utilidades\n",
        "## -----------------------------\n",
        "#def make_class_weights(y_train):\n",
        "#    classes = np.array([0, 1])\n",
        "#    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "#    return {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "#\n",
        "## -----------------------------\n",
        "## Walk-Forward Validation\n",
        "## -----------------------------\n",
        "#def walk_forward_validation(\n",
        "#    X_values, y_values,\n",
        "#    window_size=30, horizon=1,\n",
        "#    train_size=720, test_size=30, step_size=30,\n",
        "#    build_model_fn=build_lstm,\n",
        "#    epochs=10, batch_size=32, threshold=0.5,\n",
        "#    use_class_weights=True, verbose=0\n",
        "#):\n",
        "#    n = len(X_values)\n",
        "#    n_feat = X_values.shape[1]\n",
        "#\n",
        "#    y_true_all, y_proba_all, y_pred_all, fold_id_all = [], [], [], []\n",
        "#    folds_info = []\n",
        "#\n",
        "#    start = 0\n",
        "#    fold = 0\n",
        "#    while start + train_size + test_size <= n:\n",
        "#        fold += 1\n",
        "#        end_train = start + train_size\n",
        "#        end_test = end_train + test_size\n",
        "#\n",
        "#        segment_X = X_values[start:end_test]\n",
        "#        segment_y = y_values[start:end_test]\n",
        "#\n",
        "#        segment_combined = np.hstack([segment_X, segment_y.reshape(-1, 1)])\n",
        "#        Xw_all, yw_all = create_windows_multivariate_np(\n",
        "#            data=segment_combined,\n",
        "#            window_size=window_size,\n",
        "#            horizon=horizon,\n",
        "#            target_col_idx=segment_combined.shape[1]-1,\n",
        "#            shuffle=False\n",
        "#        )\n",
        "#        Xw_all = Xw_all[:, :, :n_feat]\n",
        "#\n",
        "#        seg_len = len(segment_combined)\n",
        "#        first_target_local = window_size + horizon - 1\n",
        "#        local_target_indices = np.arange(first_target_local, seg_len)\n",
        "#        global_target_indices = start + local_target_indices\n",
        "#\n",
        "#        mask_test = global_target_indices >= end_train\n",
        "#        mask_train = ~mask_test\n",
        "#\n",
        "#        Xw_tr, yw_tr = Xw_all[mask_train], yw_all[mask_train]\n",
        "#        Xw_te, yw_te = Xw_all[mask_test], yw_all[mask_test]\n",
        "#\n",
        "#        scaler = StandardScaler()\n",
        "#        Xw_tr_2d = Xw_tr.reshape(-1, n_feat)\n",
        "#        Xw_te_2d = Xw_te.reshape(-1, n_feat)\n",
        "#        scaler.fit(Xw_tr_2d)\n",
        "#        Xw_tr = scaler.transform(Xw_tr_2d).reshape(Xw_tr.shape[0], window_size, n_feat)\n",
        "#        Xw_te = scaler.transform(Xw_te_2d).reshape(Xw_te.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        class_weight = make_class_weights(yw_tr) if use_class_weights else None\n",
        "#\n",
        "#        model = build_model_fn((window_size, n_feat))\n",
        "#        model.fit(\n",
        "#            Xw_tr, yw_tr,\n",
        "#            epochs=epochs, batch_size=batch_size,\n",
        "#            verbose=verbose,\n",
        "#            class_weight=class_weight,\n",
        "#            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)]\n",
        "#        )\n",
        "#\n",
        "#        proba = model.predict(Xw_te, verbose=0).ravel()\n",
        "#        preds = (proba >= threshold).astype(int)\n",
        "#\n",
        "#        y_true_all.extend(yw_te.tolist())\n",
        "#        y_proba_all.extend(proba.tolist())\n",
        "#        y_pred_all.extend(preds.tolist())\n",
        "#        fold_id_all.extend([fold]*len(yw_te))\n",
        "#\n",
        "#        folds_info.append({\n",
        "#            \"fold\": fold,\n",
        "#            \"train_start\": start,\n",
        "#            \"train_end\": end_train-1,\n",
        "#            \"test_start\": end_train,\n",
        "#            \"test_end\": end_test-1,\n",
        "#            \"n_train_windows\": len(Xw_tr),\n",
        "#            \"n_test_windows\": len(Xw_te),\n",
        "#        })\n",
        "#\n",
        "#        start += step_size\n",
        "#\n",
        "#    y_true_all = np.array(y_true_all)\n",
        "#    y_pred_all = np.array(y_pred_all)\n",
        "#    y_proba_all = np.array(y_proba_all)\n",
        "#\n",
        "#    metrics = {\n",
        "#        \"accuracy\": accuracy_score(y_true_all, y_pred_all),\n",
        "#        \"f1\": f1_score(y_true_all, y_pred_all),\n",
        "#        \"precision\": precision_score(y_true_all, y_pred_all),\n",
        "#        \"recall\": recall_score(y_true_all, y_pred_all),\n",
        "#        \"roc_auc\": roc_auc_score(y_true_all, y_proba_all) if len(np.unique(y_true_all)) == 2 else np.nan\n",
        "#    }\n",
        "#\n",
        "#    preds_df = pd.DataFrame({\n",
        "#        \"y_true\": y_true_all,\n",
        "#        \"y_proba\": y_proba_all,\n",
        "#        \"y_pred\": y_pred_all,\n",
        "#        \"fold\": fold_id_all\n",
        "#    })\n",
        "#\n",
        "#    folds_df = pd.DataFrame(folds_info)\n",
        "#    return metrics, preds_df, folds_df\n",
        "#\n",
        "#def walk_forward_with_threshold_tuning(\n",
        "#    X_values, y_values,\n",
        "#    window_size=30, horizon=1,\n",
        "#    train_size=720, test_size=30, step_size=30,\n",
        "#    build_model_fn=build_lstm,\n",
        "#    epochs=50, batch_size=64,\n",
        "#    val_frac_in_train=0.15,   # fracción del train usada como validation (últos días)\n",
        "#    lr=1e-3,\n",
        "#    use_class_weights=True,\n",
        "#    verbose=0\n",
        "#):\n",
        "#    n = len(X_values)\n",
        "#    n_feat = X_values.shape[1]\n",
        "#\n",
        "#    y_true_all, y_pred_all, y_proba_all = [], [], []\n",
        "#\n",
        "#    start = 0\n",
        "#    fold = 0\n",
        "#    while start + train_size + test_size <= n:\n",
        "#        fold += 1\n",
        "#        end_train = start + train_size\n",
        "#        end_test = end_train + test_size\n",
        "#\n",
        "#        segment_X = X_values[start:end_test]\n",
        "#        segment_y = y_values[start:end_test]\n",
        "#\n",
        "#        segment_combined = np.hstack([segment_X, segment_y.reshape(-1,1)])\n",
        "#        Xw_all, yw_all = create_windows_multivariate_np(\n",
        "#            data=segment_combined, window_size=window_size, horizon=horizon,\n",
        "#            target_col_idx=segment_combined.shape[1]-1, shuffle=False\n",
        "#        )\n",
        "#        Xw_all = Xw_all[:, :, :n_feat]\n",
        "#\n",
        "#        seg_len = len(segment_combined)\n",
        "#        first_target_local = window_size + horizon - 1\n",
        "#        local_target_indices = np.arange(first_target_local, seg_len)\n",
        "#        global_target_indices = start + local_target_indices\n",
        "#\n",
        "#        mask_test = global_target_indices >= end_train\n",
        "#        mask_train = ~mask_test\n",
        "#\n",
        "#        Xw_tr, yw_tr = Xw_all[mask_train], yw_all[mask_train]\n",
        "#        Xw_te, yw_te = Xw_all[mask_test], yw_all[mask_test]\n",
        "#\n",
        "#        # split validation from the END of train (temporal)\n",
        "#        n_tr = len(Xw_tr)\n",
        "#        n_val = int(np.ceil(val_frac_in_train * n_tr))\n",
        "#        n_train_effective = n_tr - n_val\n",
        "#        X_tr_eff, y_tr_eff = Xw_tr[:n_train_effective], yw_tr[:n_train_effective]\n",
        "#        X_val, y_val = Xw_tr[n_train_effective:], yw_tr[n_train_effective:]\n",
        "#\n",
        "#        # scaler fit only on X_tr_eff\n",
        "#        scaler = StandardScaler()\n",
        "#        X_tr_eff_2d = X_tr_eff.reshape(-1, n_feat)\n",
        "#        scaler.fit(X_tr_eff_2d)\n",
        "#        X_tr_eff = scaler.transform(X_tr_eff_2d).reshape(X_tr_eff.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        X_val = scaler.transform(X_val.reshape(-1, n_feat)).reshape(X_val.shape[0], window_size, n_feat)\n",
        "#        Xw_te_scaled = scaler.transform(Xw_te.reshape(-1, n_feat)).reshape(Xw_te.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        class_weight = make_class_weights(y_tr_eff) if use_class_weights else None\n",
        "#\n",
        "#        # Build model and set optimizer lr\n",
        "#        model = build_model_fn((window_size, n_feat))\n",
        "#        # override optimizer lr if using Adam\n",
        "#        try:\n",
        "#            tf.keras.backend.set_value(model.optimizer.lr, lr)\n",
        "#        except Exception:\n",
        "#            pass\n",
        "#\n",
        "#        callbacks = [\n",
        "#            EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=0),\n",
        "#            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0)\n",
        "#        ]\n",
        "#\n",
        "#        model.fit(\n",
        "#            X_tr_eff, y_tr_eff,\n",
        "#            validation_data=(X_val, y_val),\n",
        "#            epochs=epochs, batch_size=batch_size,\n",
        "#            class_weight=class_weight,\n",
        "#            callbacks=callbacks, verbose=verbose\n",
        "#        )\n",
        "#\n",
        "#        # Optimizamos threshold en validation (buscar threshold que maximiza F1)\n",
        "#        val_proba = model.predict(X_val, verbose=0).ravel()\n",
        "#        best_th, best_f1 = 0.5, f1_score(y_val, (val_proba>=0.5).astype(int))\n",
        "#        for th in np.linspace(0.3, 0.7, 41):  # explora 0.30..0.70 cada 0.01\n",
        "#            f1v = f1_score(y_val, (val_proba>=th).astype(int))\n",
        "#            if f1v > best_f1:\n",
        "#                best_f1 = f1v\n",
        "#                best_th = th\n",
        "#\n",
        "#        # predecir test con ese threshold\n",
        "#        proba_test = model.predict(Xw_te_scaled, verbose=0).ravel()\n",
        "#        preds_test = (proba_test >= best_th).astype(int)\n",
        "#\n",
        "#        y_true_all.extend(yw_te.tolist())\n",
        "#        y_proba_all.extend(proba_test.tolist())\n",
        "#        y_pred_all.extend(preds_test.tolist())\n",
        "#\n",
        "#        start += step_size\n",
        "#\n",
        "#    # metrics globales\n",
        "#    from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "#    y_true_all = np.array(y_true_all)\n",
        "#    y_pred_all = np.array(y_pred_all)\n",
        "#    y_proba_all = np.array(y_proba_all)\n",
        "#\n",
        "#    metrics = {\n",
        "#        \"accuracy\": accuracy_score(y_true_all, y_pred_all),\n",
        "#        \"f1\": f1_score(y_true_all, y_pred_all),\n",
        "#        \"precision\": precision_score(y_true_all, y_pred_all),\n",
        "#        \"recall\": recall_score(y_true_all, y_pred_all),\n",
        "#        \"roc_auc\": roc_auc_score(y_true_all, y_proba_all)\n",
        "#    }\n",
        "#    return metrics\n",
        "#\n",
        "## -----------------------------\n",
        "## === EJECUCIÓN SOBRE df_bitcoin ===\n",
        "## -----------------------------\n",
        "## X = todas las columnas menos target\n",
        "#df_bitcoin[\"Open time\"] = pd.to_datetime(df_bitcoin[\"Open time\"])\n",
        "#df_bitcoin = df_bitcoin.set_index(\"Open time\")\n",
        "#\n",
        "#X_values = df_bitcoin.drop(columns=[\"Target\"]).values\n",
        "#y_values = df_bitcoin[\"Target\"].values\n",
        "#\n",
        "#\n",
        "#lookbacks = [14, 30, 60]\n",
        "#horizon = 1\n",
        "#train_size = 720\n",
        "#test_size = 30\n",
        "#step_size = 30\n",
        "#\n",
        "#results = []\n",
        "#\n",
        "#for lb in lookbacks:\n",
        "#    for model_name, builder in MODEL_BUILDERS_IMPROVED.items():\n",
        "#        print(f\"\\n>>> {model_name} | lookback={lb}\")\n",
        "#        metrics = walk_forward_with_threshold_tuning(\n",
        "#            X_values=X_values,\n",
        "#            y_values=y_values,\n",
        "#            window_size=lb,\n",
        "#            horizon=horizon,\n",
        "#            train_size=train_size,\n",
        "#            test_size=test_size,\n",
        "#            step_size=step_size,\n",
        "#            build_model_fn=builder,\n",
        "#            epochs=50,\n",
        "#            batch_size=64,\n",
        "#            val_frac_in_train=0.15,\n",
        "#            lr=1e-3,\n",
        "#            use_class_weights=True,\n",
        "#            verbose=1\n",
        "#        )\n",
        "#        results.append({\"model\": model_name, \"lookback\": lb, **metrics})\n",
        "#\n",
        "#results_df = pd.DataFrame(results).sort_values([\"roc_auc\",\"f1\",\"accuracy\"], ascending=False)\n",
        "#print(\"\\n=== RESULTADOS ===\")\n",
        "#print(results_df)"
      ],
      "metadata": {
        "id": "A0bVqkJ90XQe"
      },
      "id": "A0bVqkJ90XQe",
      "execution_count": 112,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}