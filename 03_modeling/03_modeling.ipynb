{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📊 Modelización con Redes Neuronales"
      ],
      "metadata": {
        "id": "oc3L8941w_7Q"
      },
      "id": "oc3L8941w_7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LIBRERIAS\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Establecer el nivel de advertencias a \"ignore\" para ignorar todas las advertencias\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "PRb5hdMlxdH1"
      },
      "id": "PRb5hdMlxdH1",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resetting the seeds for reproducibility\n",
        "def reset_random_seeds():\n",
        "    n = 1\n",
        "    os.environ['PYTHONHASHSEED'] = str(n)\n",
        "    tf.random.set_seed(n)\n",
        "    np.random.seed(n)\n",
        "    random.seed(n)\n",
        "\n",
        "reset_random_seeds()"
      ],
      "metadata": {
        "id": "AaKg9WJRg45w"
      },
      "id": "AaKg9WJRg45w",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 1. Importación del conjunto de datos\n",
        "El primer paso consiste en cargar el conjunto de datos en nuestro entorno de trabajo. Estos datos están almacenados en un archivo CSV llamado `btc_historical_data_eda.csv`, cuya creación y obtención se explican en el notebook `02_data_analysis.ipynb`. Para ello, se utiliza el siguiente fragmento de código:"
      ],
      "metadata": {
        "id": "_zZmB5VkxQ8B"
      },
      "id": "_zZmB5VkxQ8B"
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos CSV\n",
        "url = 'https://raw.githubusercontent.com/misanchz98/bitcoin-direction-prediction/main/02_data_analysis/data/btc_historical_data_eda.csv'\n",
        "df_bitcoin = pd.read_csv(url, parse_dates=['Open time'])\n",
        "df_bitcoin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "orqWGSQqwZJw",
        "outputId": "0fb460f5-cdbe-42b1-8ec5-27005631970c"
      },
      "id": "orqWGSQqwZJw",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Open time      Close  Number of trades  Taker buy base asset volume  \\\n",
              "0    2017-10-05    4292.43            9158.0                   351.042019   \n",
              "1    2017-10-06    4369.00            6546.0                   226.148177   \n",
              "2    2017-10-07    4423.00            4804.0                   145.313076   \n",
              "3    2017-10-08    4640.00            7580.0                   280.094854   \n",
              "4    2017-10-09    4786.95           10372.0                   350.756559   \n",
              "...         ...        ...               ...                          ...   \n",
              "2872 2025-08-16  117380.66         1179842.0                  2995.228650   \n",
              "2873 2025-08-17  117405.01         1177563.0                  2804.731130   \n",
              "2874 2025-08-18  116227.05         3345487.0                  7647.218200   \n",
              "2875 2025-08-19  112872.94         3291170.0                  8609.360780   \n",
              "2876 2025-08-20  114271.24         2998370.0                  7209.585750   \n",
              "\n",
              "      Taker buy quote asset volume    Range   Candle  Target    CMF_20  \\\n",
              "0                     1.483037e+06   245.00    83.84       1  0.081329   \n",
              "1                     9.881066e+05   125.00    50.01       1  0.090972   \n",
              "2                     6.371469e+05   166.94    54.00       1  0.072898   \n",
              "3                     1.268661e+06   233.00   215.00       1  0.064115   \n",
              "4                     1.654275e+06   339.98   146.95       0  0.105281   \n",
              "...                            ...      ...      ...     ...       ...   \n",
              "2872                  3.521588e+08   755.01    38.62       1 -0.078079   \n",
              "2873                  3.307994e+08  1402.79    24.35       0 -0.071478   \n",
              "2874                  8.850528e+08  2903.61 -1177.96       0 -0.058026   \n",
              "2875                  9.840874e+08  3993.11 -3354.11       1 -0.133646   \n",
              "2876                  8.193310e+08  2235.38  1398.29       0 -0.048524   \n",
              "\n",
              "         MFI_14  ...  c2_ta_tendencia  c3_ta_tendencia  c1_ta_momentum  \\\n",
              "0     56.225018  ...         1.426309        -0.136861        1.317719   \n",
              "1     62.048701  ...         1.684975        -0.223654        1.843789   \n",
              "2     60.780168  ...         1.837639        -0.272101        1.714315   \n",
              "3     66.225272  ...         2.655718        -0.595153        4.539268   \n",
              "4     66.423592  ...         3.068594        -0.711866        4.065484   \n",
              "...         ...  ...              ...              ...             ...   \n",
              "2872  61.679789  ...        -2.974279        -0.597347       -1.738575   \n",
              "2873  61.441782  ...        -3.056170        -0.520901       -2.679964   \n",
              "2874  54.527915  ...        -3.371373        -0.335897       -3.708156   \n",
              "2875  53.037041  ...        -4.158761         0.112011       -5.328226   \n",
              "2876  47.355321  ...        -4.010127        -0.035153       -3.323554   \n",
              "\n",
              "      c2_ta_momentum  c3_ta_momentum  c4_ta_momentum  c5_ta_momentum  \\\n",
              "0          -0.126726       -1.676720        1.289633        0.019128   \n",
              "1          -0.313902       -0.766032        1.200655        0.108543   \n",
              "2           0.851111       -1.474281       -0.169404       -0.611932   \n",
              "3          -1.327677       -1.397994        0.344940        0.095779   \n",
              "4           0.284535       -0.496135       -0.373562       -0.383308   \n",
              "...              ...             ...             ...             ...   \n",
              "2872       -0.246759        0.045690        1.947962       -0.826190   \n",
              "2873        0.452454       -1.078307        1.833305       -0.382838   \n",
              "2874        1.216496       -0.767095        1.913662        1.633951   \n",
              "2875        0.713262        0.105456        1.232647       -1.954862   \n",
              "2876       -2.507455       -1.057876        1.180263       -1.303357   \n",
              "\n",
              "      c1_ta_volatilidad  c2_ta_volatilidad  c3_ta_volatilidad  \n",
              "0             -4.644643          -0.938175          -0.259897  \n",
              "1             -4.656021          -1.404483          -0.298095  \n",
              "2             -4.658149          -1.694457          -0.310605  \n",
              "3             -4.643444          -2.930102          -0.299058  \n",
              "4             -4.619178          -3.116037          -0.259659  \n",
              "...                 ...                ...                ...  \n",
              "2872          11.130802           0.715864          -3.617415  \n",
              "2873          11.062656           0.708259          -3.717682  \n",
              "2874          11.085307           1.427748          -3.651715  \n",
              "2875          11.229262           3.161925          -3.269720  \n",
              "2876          11.207456           2.153090          -3.227203  \n",
              "\n",
              "[2877 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c64581c1-941b-467b-9be9-42c2b184fdb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open time</th>\n",
              "      <th>Close</th>\n",
              "      <th>Number of trades</th>\n",
              "      <th>Taker buy base asset volume</th>\n",
              "      <th>Taker buy quote asset volume</th>\n",
              "      <th>Range</th>\n",
              "      <th>Candle</th>\n",
              "      <th>Target</th>\n",
              "      <th>CMF_20</th>\n",
              "      <th>MFI_14</th>\n",
              "      <th>...</th>\n",
              "      <th>c2_ta_tendencia</th>\n",
              "      <th>c3_ta_tendencia</th>\n",
              "      <th>c1_ta_momentum</th>\n",
              "      <th>c2_ta_momentum</th>\n",
              "      <th>c3_ta_momentum</th>\n",
              "      <th>c4_ta_momentum</th>\n",
              "      <th>c5_ta_momentum</th>\n",
              "      <th>c1_ta_volatilidad</th>\n",
              "      <th>c2_ta_volatilidad</th>\n",
              "      <th>c3_ta_volatilidad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-10-05</td>\n",
              "      <td>4292.43</td>\n",
              "      <td>9158.0</td>\n",
              "      <td>351.042019</td>\n",
              "      <td>1.483037e+06</td>\n",
              "      <td>245.00</td>\n",
              "      <td>83.84</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081329</td>\n",
              "      <td>56.225018</td>\n",
              "      <td>...</td>\n",
              "      <td>1.426309</td>\n",
              "      <td>-0.136861</td>\n",
              "      <td>1.317719</td>\n",
              "      <td>-0.126726</td>\n",
              "      <td>-1.676720</td>\n",
              "      <td>1.289633</td>\n",
              "      <td>0.019128</td>\n",
              "      <td>-4.644643</td>\n",
              "      <td>-0.938175</td>\n",
              "      <td>-0.259897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-10-06</td>\n",
              "      <td>4369.00</td>\n",
              "      <td>6546.0</td>\n",
              "      <td>226.148177</td>\n",
              "      <td>9.881066e+05</td>\n",
              "      <td>125.00</td>\n",
              "      <td>50.01</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090972</td>\n",
              "      <td>62.048701</td>\n",
              "      <td>...</td>\n",
              "      <td>1.684975</td>\n",
              "      <td>-0.223654</td>\n",
              "      <td>1.843789</td>\n",
              "      <td>-0.313902</td>\n",
              "      <td>-0.766032</td>\n",
              "      <td>1.200655</td>\n",
              "      <td>0.108543</td>\n",
              "      <td>-4.656021</td>\n",
              "      <td>-1.404483</td>\n",
              "      <td>-0.298095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-10-07</td>\n",
              "      <td>4423.00</td>\n",
              "      <td>4804.0</td>\n",
              "      <td>145.313076</td>\n",
              "      <td>6.371469e+05</td>\n",
              "      <td>166.94</td>\n",
              "      <td>54.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.072898</td>\n",
              "      <td>60.780168</td>\n",
              "      <td>...</td>\n",
              "      <td>1.837639</td>\n",
              "      <td>-0.272101</td>\n",
              "      <td>1.714315</td>\n",
              "      <td>0.851111</td>\n",
              "      <td>-1.474281</td>\n",
              "      <td>-0.169404</td>\n",
              "      <td>-0.611932</td>\n",
              "      <td>-4.658149</td>\n",
              "      <td>-1.694457</td>\n",
              "      <td>-0.310605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-10-08</td>\n",
              "      <td>4640.00</td>\n",
              "      <td>7580.0</td>\n",
              "      <td>280.094854</td>\n",
              "      <td>1.268661e+06</td>\n",
              "      <td>233.00</td>\n",
              "      <td>215.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.064115</td>\n",
              "      <td>66.225272</td>\n",
              "      <td>...</td>\n",
              "      <td>2.655718</td>\n",
              "      <td>-0.595153</td>\n",
              "      <td>4.539268</td>\n",
              "      <td>-1.327677</td>\n",
              "      <td>-1.397994</td>\n",
              "      <td>0.344940</td>\n",
              "      <td>0.095779</td>\n",
              "      <td>-4.643444</td>\n",
              "      <td>-2.930102</td>\n",
              "      <td>-0.299058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-10-09</td>\n",
              "      <td>4786.95</td>\n",
              "      <td>10372.0</td>\n",
              "      <td>350.756559</td>\n",
              "      <td>1.654275e+06</td>\n",
              "      <td>339.98</td>\n",
              "      <td>146.95</td>\n",
              "      <td>0</td>\n",
              "      <td>0.105281</td>\n",
              "      <td>66.423592</td>\n",
              "      <td>...</td>\n",
              "      <td>3.068594</td>\n",
              "      <td>-0.711866</td>\n",
              "      <td>4.065484</td>\n",
              "      <td>0.284535</td>\n",
              "      <td>-0.496135</td>\n",
              "      <td>-0.373562</td>\n",
              "      <td>-0.383308</td>\n",
              "      <td>-4.619178</td>\n",
              "      <td>-3.116037</td>\n",
              "      <td>-0.259659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2872</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>117380.66</td>\n",
              "      <td>1179842.0</td>\n",
              "      <td>2995.228650</td>\n",
              "      <td>3.521588e+08</td>\n",
              "      <td>755.01</td>\n",
              "      <td>38.62</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.078079</td>\n",
              "      <td>61.679789</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.974279</td>\n",
              "      <td>-0.597347</td>\n",
              "      <td>-1.738575</td>\n",
              "      <td>-0.246759</td>\n",
              "      <td>0.045690</td>\n",
              "      <td>1.947962</td>\n",
              "      <td>-0.826190</td>\n",
              "      <td>11.130802</td>\n",
              "      <td>0.715864</td>\n",
              "      <td>-3.617415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2873</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>117405.01</td>\n",
              "      <td>1177563.0</td>\n",
              "      <td>2804.731130</td>\n",
              "      <td>3.307994e+08</td>\n",
              "      <td>1402.79</td>\n",
              "      <td>24.35</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.071478</td>\n",
              "      <td>61.441782</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.056170</td>\n",
              "      <td>-0.520901</td>\n",
              "      <td>-2.679964</td>\n",
              "      <td>0.452454</td>\n",
              "      <td>-1.078307</td>\n",
              "      <td>1.833305</td>\n",
              "      <td>-0.382838</td>\n",
              "      <td>11.062656</td>\n",
              "      <td>0.708259</td>\n",
              "      <td>-3.717682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2874</th>\n",
              "      <td>2025-08-18</td>\n",
              "      <td>116227.05</td>\n",
              "      <td>3345487.0</td>\n",
              "      <td>7647.218200</td>\n",
              "      <td>8.850528e+08</td>\n",
              "      <td>2903.61</td>\n",
              "      <td>-1177.96</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.058026</td>\n",
              "      <td>54.527915</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.371373</td>\n",
              "      <td>-0.335897</td>\n",
              "      <td>-3.708156</td>\n",
              "      <td>1.216496</td>\n",
              "      <td>-0.767095</td>\n",
              "      <td>1.913662</td>\n",
              "      <td>1.633951</td>\n",
              "      <td>11.085307</td>\n",
              "      <td>1.427748</td>\n",
              "      <td>-3.651715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2875</th>\n",
              "      <td>2025-08-19</td>\n",
              "      <td>112872.94</td>\n",
              "      <td>3291170.0</td>\n",
              "      <td>8609.360780</td>\n",
              "      <td>9.840874e+08</td>\n",
              "      <td>3993.11</td>\n",
              "      <td>-3354.11</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.133646</td>\n",
              "      <td>53.037041</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.158761</td>\n",
              "      <td>0.112011</td>\n",
              "      <td>-5.328226</td>\n",
              "      <td>0.713262</td>\n",
              "      <td>0.105456</td>\n",
              "      <td>1.232647</td>\n",
              "      <td>-1.954862</td>\n",
              "      <td>11.229262</td>\n",
              "      <td>3.161925</td>\n",
              "      <td>-3.269720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>2025-08-20</td>\n",
              "      <td>114271.24</td>\n",
              "      <td>2998370.0</td>\n",
              "      <td>7209.585750</td>\n",
              "      <td>8.193310e+08</td>\n",
              "      <td>2235.38</td>\n",
              "      <td>1398.29</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.048524</td>\n",
              "      <td>47.355321</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.010127</td>\n",
              "      <td>-0.035153</td>\n",
              "      <td>-3.323554</td>\n",
              "      <td>-2.507455</td>\n",
              "      <td>-1.057876</td>\n",
              "      <td>1.180263</td>\n",
              "      <td>-1.303357</td>\n",
              "      <td>11.207456</td>\n",
              "      <td>2.153090</td>\n",
              "      <td>-3.227203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2877 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c64581c1-941b-467b-9be9-42c2b184fdb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c64581c1-941b-467b-9be9-42c2b184fdb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c64581c1-941b-467b-9be9-42c2b184fdb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f93b470c-4446-4809-b6f0-27eac529330f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f93b470c-4446-4809-b6f0-27eac529330f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f93b470c-4446-4809-b6f0-27eac529330f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4e6af001-9b99-453f-bfb8-15aea6d0966b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_bitcoin')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e6af001-9b99-453f-bfb8-15aea6d0966b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_bitcoin');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_bitcoin"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 2. División del conjunto de datos"
      ],
      "metadata": {
        "id": "gpxUhj2LfI3z"
      },
      "id": "gpxUhj2LfI3z"
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_bitcoin.drop(['Open time', 'Target'], axis=1)\n",
        "y = df_bitcoin['Target']\n",
        "\n",
        "# separate training data from testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# scale the input data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Reshape X_train and X_test if they are 1D\n",
        "if X_train.ndim == 1:\n",
        "    X_train = X_train.to_numpy().reshape(-1, 1)\n",
        "if X_test.ndim == 1:\n",
        "    X_test = X_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# reshape the input data for CNN-LSTM (samples, timesteps, features)\n",
        "def create_sequences(data, timesteps):\n",
        "    X = []\n",
        "    for i in range(len(data) - timesteps + 1):\n",
        "        X.append(data[i:i + timesteps])\n",
        "    return np.array(X)\n",
        "\n",
        "timesteps = 7\n",
        "X_train_reshaped = create_sequences(X_train_scaled, timesteps)\n",
        "X_test_reshaped = create_sequences(X_test_scaled, timesteps)\n",
        "y_train = y_train[timesteps - 1:]\n",
        "y_test = y_test[timesteps - 1:]"
      ],
      "metadata": {
        "id": "rtEjAgeufewH"
      },
      "id": "rtEjAgeufewH",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "ENlCQ09tmahV"
      },
      "id": "ENlCQ09tmahV"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1_score_2(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "_rBNXkQCsz8S"
      },
      "id": "_rBNXkQCsz8S",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # binaria\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[metrics.BinaryAccuracy(), metrics.Precision(), metrics.Recall(), f1_score_2]\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_binary_accuracy',  # mejor usar val_binary_accuracy\n",
        "    patience=50,\n",
        "    mode='max',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train.astype('float32'),  # convertir a float32\n",
        "    epochs=100,\n",
        "    batch_size=50,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jheEAEKQs72Y",
        "outputId": "44671316-bc83-4823-cc9d-935a033a48a0"
      },
      "id": "jheEAEKQs72Y",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - binary_accuracy: 0.5263 - f1_score_2: 0.5756 - loss: 0.6935 - precision_10: 0.5273 - recall_10: 0.6440 - val_binary_accuracy: 0.5217 - val_f1_score_2: 0.6506 - val_loss: 0.6932 - val_precision_10: 0.5172 - val_recall_10: 0.8974\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5163 - f1_score_2: 0.5886 - loss: 0.6961 - precision_10: 0.5166 - recall_10: 0.7020 - val_binary_accuracy: 0.5043 - val_f1_score_2: 0.4701 - val_loss: 0.6944 - val_precision_10: 0.5138 - val_recall_10: 0.4786\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5402 - f1_score_2: 0.5995 - loss: 0.6936 - precision_10: 0.5356 - recall_10: 0.7044 - val_binary_accuracy: 0.5478 - val_f1_score_2: 0.5979 - val_loss: 0.6916 - val_precision_10: 0.5414 - val_recall_10: 0.7265\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5327 - f1_score_2: 0.5970 - loss: 0.6885 - precision_10: 0.5292 - recall_10: 0.7007 - val_binary_accuracy: 0.4957 - val_f1_score_2: 0.5509 - val_loss: 0.6912 - val_precision_10: 0.5032 - val_recall_10: 0.6752\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5706 - f1_score_2: 0.6078 - loss: 0.6856 - precision_10: 0.5653 - recall_10: 0.6674 - val_binary_accuracy: 0.5261 - val_f1_score_2: 0.5945 - val_loss: 0.6896 - val_precision_10: 0.5250 - val_recall_10: 0.7179\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5619 - f1_score_2: 0.6103 - loss: 0.6828 - precision_10: 0.5548 - recall_10: 0.6905 - val_binary_accuracy: 0.4696 - val_f1_score_2: 0.5025 - val_loss: 0.6992 - val_precision_10: 0.4812 - val_recall_10: 0.5470\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5671 - f1_score_2: 0.6075 - loss: 0.6816 - precision_10: 0.5618 - recall_10: 0.6696 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.5686 - val_loss: 0.7005 - val_precision_10: 0.4939 - val_recall_10: 0.6923\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5740 - f1_score_2: 0.6033 - loss: 0.6767 - precision_10: 0.5697 - recall_10: 0.6563 - val_binary_accuracy: 0.5130 - val_f1_score_2: 0.6463 - val_loss: 0.7165 - val_precision_10: 0.5123 - val_recall_10: 0.8889\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5735 - f1_score_2: 0.6092 - loss: 0.6782 - precision_10: 0.5688 - recall_10: 0.6636 - val_binary_accuracy: 0.4870 - val_f1_score_2: 0.4925 - val_loss: 0.7311 - val_precision_10: 0.4959 - val_recall_10: 0.5128\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5935 - f1_score_2: 0.6295 - loss: 0.6624 - precision_10: 0.5844 - recall_10: 0.6920 - val_binary_accuracy: 0.5261 - val_f1_score_2: 0.6288 - val_loss: 0.7173 - val_precision_10: 0.5217 - val_recall_10: 0.8205\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6031 - f1_score_2: 0.6490 - loss: 0.6532 - precision_10: 0.5873 - recall_10: 0.7404 - val_binary_accuracy: 0.4913 - val_f1_score_2: 0.5617 - val_loss: 0.7249 - val_precision_10: 0.5000 - val_recall_10: 0.6667\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5954 - f1_score_2: 0.6228 - loss: 0.6600 - precision_10: 0.5891 - recall_10: 0.6763 - val_binary_accuracy: 0.5000 - val_f1_score_2: 0.5730 - val_loss: 0.7431 - val_precision_10: 0.5060 - val_recall_10: 0.7179\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6201 - f1_score_2: 0.6610 - loss: 0.6361 - precision_10: 0.6022 - recall_10: 0.7498 - val_binary_accuracy: 0.5087 - val_f1_score_2: 0.6376 - val_loss: 0.7501 - val_precision_10: 0.5101 - val_recall_10: 0.8632\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6241 - f1_score_2: 0.6660 - loss: 0.6342 - precision_10: 0.6058 - recall_10: 0.7510 - val_binary_accuracy: 0.5217 - val_f1_score_2: 0.6228 - val_loss: 0.7395 - val_precision_10: 0.5198 - val_recall_10: 0.7863\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6326 - f1_score_2: 0.6753 - loss: 0.6205 - precision_10: 0.6115 - recall_10: 0.7658 - val_binary_accuracy: 0.5087 - val_f1_score_2: 0.5297 - val_loss: 0.7457 - val_precision_10: 0.5154 - val_recall_10: 0.5726\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6665 - f1_score_2: 0.6848 - loss: 0.6082 - precision_10: 0.6524 - recall_10: 0.7360 - val_binary_accuracy: 0.4739 - val_f1_score_2: 0.4429 - val_loss: 0.8175 - val_precision_10: 0.4804 - val_recall_10: 0.4188\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6416 - f1_score_2: 0.6615 - loss: 0.6103 - precision_10: 0.6321 - recall_10: 0.7049 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.4925 - val_loss: 0.8925 - val_precision_10: 0.4921 - val_recall_10: 0.5299\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6573 - f1_score_2: 0.6663 - loss: 0.5892 - precision_10: 0.6535 - recall_10: 0.6912 - val_binary_accuracy: 0.5130 - val_f1_score_2: 0.4679 - val_loss: 0.9885 - val_precision_10: 0.5253 - val_recall_10: 0.4444\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6834 - f1_score_2: 0.7144 - loss: 0.5505 - precision_10: 0.6533 - recall_10: 0.8050 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.5308 - val_loss: 0.9337 - val_precision_10: 0.4929 - val_recall_10: 0.5897\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6736 - f1_score_2: 0.6967 - loss: 0.5648 - precision_10: 0.6535 - recall_10: 0.7607 - val_binary_accuracy: 0.4783 - val_f1_score_2: 0.4944 - val_loss: 0.8620 - val_precision_10: 0.4876 - val_recall_10: 0.5043\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7000 - f1_score_2: 0.7120 - loss: 0.5357 - precision_10: 0.6849 - recall_10: 0.7573 - val_binary_accuracy: 0.5217 - val_f1_score_2: 0.4804 - val_loss: 0.8778 - val_precision_10: 0.5354 - val_recall_10: 0.4530\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7265 - f1_score_2: 0.7412 - loss: 0.5084 - precision_10: 0.7031 - recall_10: 0.7984 - val_binary_accuracy: 0.5174 - val_f1_score_2: 0.4687 - val_loss: 1.0271 - val_precision_10: 0.5312 - val_recall_10: 0.4359\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7382 - f1_score_2: 0.7513 - loss: 0.4981 - precision_10: 0.7150 - recall_10: 0.8044 - val_binary_accuracy: 0.4913 - val_f1_score_2: 0.4652 - val_loss: 1.1371 - val_precision_10: 0.5000 - val_recall_10: 0.4444\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7394 - f1_score_2: 0.7482 - loss: 0.4965 - precision_10: 0.7248 - recall_10: 0.7847 - val_binary_accuracy: 0.4957 - val_f1_score_2: 0.4805 - val_loss: 1.1505 - val_precision_10: 0.5047 - val_recall_10: 0.4615\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7383 - f1_score_2: 0.7471 - loss: 0.4790 - precision_10: 0.7294 - recall_10: 0.7721 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.4915 - val_loss: 1.3067 - val_precision_10: 0.4915 - val_recall_10: 0.4957\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7468 - f1_score_2: 0.7589 - loss: 0.4535 - precision_10: 0.7270 - recall_10: 0.8037 - val_binary_accuracy: 0.5043 - val_f1_score_2: 0.4835 - val_loss: 1.2790 - val_precision_10: 0.5143 - val_recall_10: 0.4615\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7455 - f1_score_2: 0.7594 - loss: 0.4777 - precision_10: 0.7257 - recall_10: 0.8041 - val_binary_accuracy: 0.5130 - val_f1_score_2: 0.5284 - val_loss: 1.2908 - val_precision_10: 0.5207 - val_recall_10: 0.5385\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7617 - f1_score_2: 0.7769 - loss: 0.4378 - precision_10: 0.7328 - recall_10: 0.8376 - val_binary_accuracy: 0.4913 - val_f1_score_2: 0.4347 - val_loss: 1.4715 - val_precision_10: 0.5000 - val_recall_10: 0.3846\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7819 - f1_score_2: 0.7914 - loss: 0.3995 - precision_10: 0.7609 - recall_10: 0.8330 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.3885 - val_loss: 1.4822 - val_precision_10: 0.4872 - val_recall_10: 0.3248\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7864 - f1_score_2: 0.7919 - loss: 0.4094 - precision_10: 0.7763 - recall_10: 0.8159 - val_binary_accuracy: 0.4609 - val_f1_score_2: 0.4454 - val_loss: 1.4397 - val_precision_10: 0.4673 - val_recall_10: 0.4274\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7967 - f1_score_2: 0.8072 - loss: 0.3753 - precision_10: 0.7755 - recall_10: 0.8484 - val_binary_accuracy: 0.4913 - val_f1_score_2: 0.4275 - val_loss: 1.5120 - val_precision_10: 0.5000 - val_recall_10: 0.3761\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8063 - f1_score_2: 0.8076 - loss: 0.3755 - precision_10: 0.7985 - recall_10: 0.8277 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.4671 - val_loss: 1.7996 - val_precision_10: 0.4906 - val_recall_10: 0.4444\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8396 - f1_score_2: 0.8400 - loss: 0.3426 - precision_10: 0.8425 - recall_10: 0.8419 - val_binary_accuracy: 0.5000 - val_f1_score_2: 0.5147 - val_loss: 1.9157 - val_precision_10: 0.5082 - val_recall_10: 0.5299\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8272 - f1_score_2: 0.8274 - loss: 0.3558 - precision_10: 0.8256 - recall_10: 0.8370 - val_binary_accuracy: 0.4913 - val_f1_score_2: 0.4447 - val_loss: 1.6442 - val_precision_10: 0.5000 - val_recall_10: 0.4103\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8490 - f1_score_2: 0.8499 - loss: 0.3096 - precision_10: 0.8471 - recall_10: 0.8581 - val_binary_accuracy: 0.5087 - val_f1_score_2: 0.4446 - val_loss: 2.1066 - val_precision_10: 0.5233 - val_recall_10: 0.3846\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8500 - f1_score_2: 0.8492 - loss: 0.3243 - precision_10: 0.8490 - recall_10: 0.8576 - val_binary_accuracy: 0.4652 - val_f1_score_2: 0.2910 - val_loss: 1.9653 - val_precision_10: 0.4483 - val_recall_10: 0.2222\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8687 - f1_score_2: 0.8657 - loss: 0.2937 - precision_10: 0.8897 - recall_10: 0.8466 - val_binary_accuracy: 0.4783 - val_f1_score_2: 0.3860 - val_loss: 1.6157 - val_precision_10: 0.4815 - val_recall_10: 0.3333\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8872 - f1_score_2: 0.8874 - loss: 0.2541 - precision_10: 0.8907 - recall_10: 0.8869 - val_binary_accuracy: 0.4870 - val_f1_score_2: 0.3712 - val_loss: 1.8583 - val_precision_10: 0.4933 - val_recall_10: 0.3162\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8965 - f1_score_2: 0.8950 - loss: 0.2276 - precision_10: 0.9030 - recall_10: 0.8918 - val_binary_accuracy: 0.4739 - val_f1_score_2: 0.3646 - val_loss: 2.0055 - val_precision_10: 0.4737 - val_recall_10: 0.3077\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9029 - f1_score_2: 0.9038 - loss: 0.2150 - precision_10: 0.8978 - recall_10: 0.9131 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.3621 - val_loss: 2.1967 - val_precision_10: 0.4857 - val_recall_10: 0.2906\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9093 - f1_score_2: 0.9092 - loss: 0.2045 - precision_10: 0.9091 - recall_10: 0.9128 - val_binary_accuracy: 0.5348 - val_f1_score_2: 0.4825 - val_loss: 1.9806 - val_precision_10: 0.5556 - val_recall_10: 0.4274\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9175 - f1_score_2: 0.9171 - loss: 0.2028 - precision_10: 0.9212 - recall_10: 0.9160 - val_binary_accuracy: 0.5043 - val_f1_score_2: 0.4823 - val_loss: 2.1358 - val_precision_10: 0.5143 - val_recall_10: 0.4615\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9307 - f1_score_2: 0.9308 - loss: 0.1748 - precision_10: 0.9303 - recall_10: 0.9334 - val_binary_accuracy: 0.5217 - val_f1_score_2: 0.5207 - val_loss: 1.9619 - val_precision_10: 0.5315 - val_recall_10: 0.5043\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9279 - f1_score_2: 0.9292 - loss: 0.1758 - precision_10: 0.9282 - recall_10: 0.9303 - val_binary_accuracy: 0.5217 - val_f1_score_2: 0.4961 - val_loss: 2.0140 - val_precision_10: 0.5333 - val_recall_10: 0.4786\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9330 - f1_score_2: 0.9327 - loss: 0.1803 - precision_10: 0.9381 - recall_10: 0.9292 - val_binary_accuracy: 0.5348 - val_f1_score_2: 0.4619 - val_loss: 1.9590 - val_precision_10: 0.5595 - val_recall_10: 0.4017\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9223 - f1_score_2: 0.9226 - loss: 0.1798 - precision_10: 0.9202 - recall_10: 0.9272 - val_binary_accuracy: 0.5087 - val_f1_score_2: 0.4201 - val_loss: 2.0335 - val_precision_10: 0.5250 - val_recall_10: 0.3590\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9286 - f1_score_2: 0.9277 - loss: 0.1905 - precision_10: 0.9263 - recall_10: 0.9335 - val_binary_accuracy: 0.4826 - val_f1_score_2: 0.4039 - val_loss: 1.9284 - val_precision_10: 0.4881 - val_recall_10: 0.3504\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9538 - f1_score_2: 0.9514 - loss: 0.1174 - precision_10: 0.9488 - recall_10: 0.9607 - val_binary_accuracy: 0.5087 - val_f1_score_2: 0.4075 - val_loss: 2.4914 - val_precision_10: 0.5270 - val_recall_10: 0.3333\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9688 - f1_score_2: 0.9688 - loss: 0.0899 - precision_10: 0.9815 - recall_10: 0.9569 - val_binary_accuracy: 0.5130 - val_f1_score_2: 0.4295 - val_loss: 2.4648 - val_precision_10: 0.5301 - val_recall_10: 0.3761\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9700 - f1_score_2: 0.9694 - loss: 0.0930 - precision_10: 0.9691 - recall_10: 0.9720 - val_binary_accuracy: 0.5348 - val_f1_score_2: 0.4889 - val_loss: 2.5679 - val_precision_10: 0.5532 - val_recall_10: 0.4444\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9734 - f1_score_2: 0.9737 - loss: 0.0743 - precision_10: 0.9680 - recall_10: 0.9802 - val_binary_accuracy: 0.4957 - val_f1_score_2: 0.4388 - val_loss: 2.8054 - val_precision_10: 0.5055 - val_recall_10: 0.3932\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9757 - f1_score_2: 0.9766 - loss: 0.0647 - precision_10: 0.9800 - recall_10: 0.9721 - val_binary_accuracy: 0.5217 - val_f1_score_2: 0.4471 - val_loss: 2.7342 - val_precision_10: 0.5432 - val_recall_10: 0.3761\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9671 - f1_score_2: 0.9659 - loss: 0.0852 - precision_10: 0.9626 - recall_10: 0.9729 - val_binary_accuracy: 0.5261 - val_f1_score_2: 0.4572 - val_loss: 2.7632 - val_precision_10: 0.5476 - val_recall_10: 0.3932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# evaluate the prediction performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iamdVWptEOx",
        "outputId": "0147209c-df2d-4efe-90bb-3e1ba1b11a99"
      },
      "id": "3iamdVWptEOx",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
            "Accuracy: 0.5\n",
            "Precision: 0.5407407407407407\n",
            "Recall: 0.24662162162162163\n",
            "F1-score: 0.33874709976798145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Walk-Forward en df_bitcoin\n",
        "# =========================================\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.keras import Sequential\n",
        "#from tensorflow.keras.layers import LSTM, GRU, Dense, Conv1D, MaxPooling1D, Dropout\n",
        "#from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "#from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "#from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "#\n",
        "## -----------------------------\n",
        "## Funciones de ventanas (las tuyas)\n",
        "## -----------------------------\n",
        "#def create_windows_multivariate_np(data, window_size, horizon, target_col_idx, shuffle=False):\n",
        "#    if isinstance(data, pd.DataFrame):\n",
        "#        data = data.values\n",
        "#    X, y = [], []\n",
        "#    for i in range(len(data) - window_size - horizon + 1):\n",
        "#        X.append(data[i:i+window_size, :])\n",
        "#        y.append(data[i+window_size+horizon-1, target_col_idx])\n",
        "#    X, y = np.array(X), np.array(y)\n",
        "#    if shuffle:\n",
        "#        indices = np.arange(X.shape[0])\n",
        "#        np.random.shuffle(indices)\n",
        "#        X, y = X[indices], y[indices]\n",
        "#    return X, y\n",
        "#\n",
        "## -----------------------------\n",
        "## Builders de modelos\n",
        "## -----------------------------\n",
        "#def build_lstm(input_shape):\n",
        "#    model = Sequential([\n",
        "#        LSTM(64, input_shape=input_shape),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_gru(input_shape):\n",
        "#    model = Sequential([\n",
        "#        GRU(64, input_shape=input_shape),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_lstm(input_shape):\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        LSTM(64),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_gru(input_shape):\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        GRU(64),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#MODEL_BUILDERS = {\n",
        "#    \"LSTM\": build_lstm,\n",
        "#    \"GRU\": build_gru,\n",
        "#    \"CNN+LSTM\": build_cnn_lstm,\n",
        "#    \"CNN+GRU\": build_cnn_gru\n",
        "#}\n",
        "#\n",
        "## 1. BUILDERS DE MODELOS MEJORADOS\n",
        "#def build_lstm_improved(input_shape):\n",
        "#    \"\"\"LSTM mejorado con mejor arquitectura\"\"\"\n",
        "#    model = Sequential([\n",
        "#        LSTM(128, return_sequences=True, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        LSTM(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_gru_improved(input_shape):\n",
        "#    \"\"\"GRU mejorado con regularización\"\"\"\n",
        "#    model = Sequential([\n",
        "#        GRU(128, return_sequences=True, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        GRU(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_lstm_improved(input_shape):\n",
        "#    \"\"\"CNN+LSTM mejorado con múltiples escalas\"\"\"\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=input_shape),\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        Dropout(0.2),\n",
        "#        LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        LSTM(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_gru_improved(input_shape):\n",
        "#    \"\"\"CNN+GRU mejorado\"\"\"\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=input_shape),\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        Dropout(0.2),\n",
        "#        GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        GRU(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "## Diccionario de modelos\n",
        "#MODEL_BUILDERS_IMPROVED = {\n",
        "#    \"LSTM\": build_lstm_improved,\n",
        "#    \"GRU\": build_gru_improved,\n",
        "#    \"CNN+LSTM\": build_cnn_lstm_improved,\n",
        "#    \"CNN+GRU\": build_cnn_gru_improved\n",
        "#}\n",
        "#\n",
        "#\n",
        "## -----------------------------\n",
        "## Utilidades\n",
        "## -----------------------------\n",
        "#def make_class_weights(y_train):\n",
        "#    classes = np.array([0, 1])\n",
        "#    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "#    return {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "#\n",
        "## -----------------------------\n",
        "## Walk-Forward Validation\n",
        "## -----------------------------\n",
        "#def walk_forward_validation(\n",
        "#    X_values, y_values,\n",
        "#    window_size=30, horizon=1,\n",
        "#    train_size=720, test_size=30, step_size=30,\n",
        "#    build_model_fn=build_lstm,\n",
        "#    epochs=10, batch_size=32, threshold=0.5,\n",
        "#    use_class_weights=True, verbose=0\n",
        "#):\n",
        "#    n = len(X_values)\n",
        "#    n_feat = X_values.shape[1]\n",
        "#\n",
        "#    y_true_all, y_proba_all, y_pred_all, fold_id_all = [], [], [], []\n",
        "#    folds_info = []\n",
        "#\n",
        "#    start = 0\n",
        "#    fold = 0\n",
        "#    while start + train_size + test_size <= n:\n",
        "#        fold += 1\n",
        "#        end_train = start + train_size\n",
        "#        end_test = end_train + test_size\n",
        "#\n",
        "#        segment_X = X_values[start:end_test]\n",
        "#        segment_y = y_values[start:end_test]\n",
        "#\n",
        "#        segment_combined = np.hstack([segment_X, segment_y.reshape(-1, 1)])\n",
        "#        Xw_all, yw_all = create_windows_multivariate_np(\n",
        "#            data=segment_combined,\n",
        "#            window_size=window_size,\n",
        "#            horizon=horizon,\n",
        "#            target_col_idx=segment_combined.shape[1]-1,\n",
        "#            shuffle=False\n",
        "#        )\n",
        "#        Xw_all = Xw_all[:, :, :n_feat]\n",
        "#\n",
        "#        seg_len = len(segment_combined)\n",
        "#        first_target_local = window_size + horizon - 1\n",
        "#        local_target_indices = np.arange(first_target_local, seg_len)\n",
        "#        global_target_indices = start + local_target_indices\n",
        "#\n",
        "#        mask_test = global_target_indices >= end_train\n",
        "#        mask_train = ~mask_test\n",
        "#\n",
        "#        Xw_tr, yw_tr = Xw_all[mask_train], yw_all[mask_train]\n",
        "#        Xw_te, yw_te = Xw_all[mask_test], yw_all[mask_test]\n",
        "#\n",
        "#        scaler = StandardScaler()\n",
        "#        Xw_tr_2d = Xw_tr.reshape(-1, n_feat)\n",
        "#        Xw_te_2d = Xw_te.reshape(-1, n_feat)\n",
        "#        scaler.fit(Xw_tr_2d)\n",
        "#        Xw_tr = scaler.transform(Xw_tr_2d).reshape(Xw_tr.shape[0], window_size, n_feat)\n",
        "#        Xw_te = scaler.transform(Xw_te_2d).reshape(Xw_te.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        class_weight = make_class_weights(yw_tr) if use_class_weights else None\n",
        "#\n",
        "#        model = build_model_fn((window_size, n_feat))\n",
        "#        model.fit(\n",
        "#            Xw_tr, yw_tr,\n",
        "#            epochs=epochs, batch_size=batch_size,\n",
        "#            verbose=verbose,\n",
        "#            class_weight=class_weight,\n",
        "#            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)]\n",
        "#        )\n",
        "#\n",
        "#        proba = model.predict(Xw_te, verbose=0).ravel()\n",
        "#        preds = (proba >= threshold).astype(int)\n",
        "#\n",
        "#        y_true_all.extend(yw_te.tolist())\n",
        "#        y_proba_all.extend(proba.tolist())\n",
        "#        y_pred_all.extend(preds.tolist())\n",
        "#        fold_id_all.extend([fold]*len(yw_te))\n",
        "#\n",
        "#        folds_info.append({\n",
        "#            \"fold\": fold,\n",
        "#            \"train_start\": start,\n",
        "#            \"train_end\": end_train-1,\n",
        "#            \"test_start\": end_train,\n",
        "#            \"test_end\": end_test-1,\n",
        "#            \"n_train_windows\": len(Xw_tr),\n",
        "#            \"n_test_windows\": len(Xw_te),\n",
        "#        })\n",
        "#\n",
        "#        start += step_size\n",
        "#\n",
        "#    y_true_all = np.array(y_true_all)\n",
        "#    y_pred_all = np.array(y_pred_all)\n",
        "#    y_proba_all = np.array(y_proba_all)\n",
        "#\n",
        "#    metrics = {\n",
        "#        \"accuracy\": accuracy_score(y_true_all, y_pred_all),\n",
        "#        \"f1\": f1_score(y_true_all, y_pred_all),\n",
        "#        \"precision\": precision_score(y_true_all, y_pred_all),\n",
        "#        \"recall\": recall_score(y_true_all, y_pred_all),\n",
        "#        \"roc_auc\": roc_auc_score(y_true_all, y_proba_all) if len(np.unique(y_true_all)) == 2 else np.nan\n",
        "#    }\n",
        "#\n",
        "#    preds_df = pd.DataFrame({\n",
        "#        \"y_true\": y_true_all,\n",
        "#        \"y_proba\": y_proba_all,\n",
        "#        \"y_pred\": y_pred_all,\n",
        "#        \"fold\": fold_id_all\n",
        "#    })\n",
        "#\n",
        "#    folds_df = pd.DataFrame(folds_info)\n",
        "#    return metrics, preds_df, folds_df\n",
        "#\n",
        "#def walk_forward_with_threshold_tuning(\n",
        "#    X_values, y_values,\n",
        "#    window_size=30, horizon=1,\n",
        "#    train_size=720, test_size=30, step_size=30,\n",
        "#    build_model_fn=build_lstm,\n",
        "#    epochs=50, batch_size=64,\n",
        "#    val_frac_in_train=0.15,   # fracción del train usada como validation (últos días)\n",
        "#    lr=1e-3,\n",
        "#    use_class_weights=True,\n",
        "#    verbose=0\n",
        "#):\n",
        "#    n = len(X_values)\n",
        "#    n_feat = X_values.shape[1]\n",
        "#\n",
        "#    y_true_all, y_pred_all, y_proba_all = [], [], []\n",
        "#\n",
        "#    start = 0\n",
        "#    fold = 0\n",
        "#    while start + train_size + test_size <= n:\n",
        "#        fold += 1\n",
        "#        end_train = start + train_size\n",
        "#        end_test = end_train + test_size\n",
        "#\n",
        "#        segment_X = X_values[start:end_test]\n",
        "#        segment_y = y_values[start:end_test]\n",
        "#\n",
        "#        segment_combined = np.hstack([segment_X, segment_y.reshape(-1,1)])\n",
        "#        Xw_all, yw_all = create_windows_multivariate_np(\n",
        "#            data=segment_combined, window_size=window_size, horizon=horizon,\n",
        "#            target_col_idx=segment_combined.shape[1]-1, shuffle=False\n",
        "#        )\n",
        "#        Xw_all = Xw_all[:, :, :n_feat]\n",
        "#\n",
        "#        seg_len = len(segment_combined)\n",
        "#        first_target_local = window_size + horizon - 1\n",
        "#        local_target_indices = np.arange(first_target_local, seg_len)\n",
        "#        global_target_indices = start + local_target_indices\n",
        "#\n",
        "#        mask_test = global_target_indices >= end_train\n",
        "#        mask_train = ~mask_test\n",
        "#\n",
        "#        Xw_tr, yw_tr = Xw_all[mask_train], yw_all[mask_train]\n",
        "#        Xw_te, yw_te = Xw_all[mask_test], yw_all[mask_test]\n",
        "#\n",
        "#        # split validation from the END of train (temporal)\n",
        "#        n_tr = len(Xw_tr)\n",
        "#        n_val = int(np.ceil(val_frac_in_train * n_tr))\n",
        "#        n_train_effective = n_tr - n_val\n",
        "#        X_tr_eff, y_tr_eff = Xw_tr[:n_train_effective], yw_tr[:n_train_effective]\n",
        "#        X_val, y_val = Xw_tr[n_train_effective:], yw_tr[n_train_effective:]\n",
        "#\n",
        "#        # scaler fit only on X_tr_eff\n",
        "#        scaler = StandardScaler()\n",
        "#        X_tr_eff_2d = X_tr_eff.reshape(-1, n_feat)\n",
        "#        scaler.fit(X_tr_eff_2d)\n",
        "#        X_tr_eff = scaler.transform(X_tr_eff_2d).reshape(X_tr_eff.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        X_val = scaler.transform(X_val.reshape(-1, n_feat)).reshape(X_val.shape[0], window_size, n_feat)\n",
        "#        Xw_te_scaled = scaler.transform(Xw_te.reshape(-1, n_feat)).reshape(Xw_te.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        class_weight = make_class_weights(y_tr_eff) if use_class_weights else None\n",
        "#\n",
        "#        # Build model and set optimizer lr\n",
        "#        model = build_model_fn((window_size, n_feat))\n",
        "#        # override optimizer lr if using Adam\n",
        "#        try:\n",
        "#            tf.keras.backend.set_value(model.optimizer.lr, lr)\n",
        "#        except Exception:\n",
        "#            pass\n",
        "#\n",
        "#        callbacks = [\n",
        "#            EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=0),\n",
        "#            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0)\n",
        "#        ]\n",
        "#\n",
        "#        model.fit(\n",
        "#            X_tr_eff, y_tr_eff,\n",
        "#            validation_data=(X_val, y_val),\n",
        "#            epochs=epochs, batch_size=batch_size,\n",
        "#            class_weight=class_weight,\n",
        "#            callbacks=callbacks, verbose=verbose\n",
        "#        )\n",
        "#\n",
        "#        # Optimizamos threshold en validation (buscar threshold que maximiza F1)\n",
        "#        val_proba = model.predict(X_val, verbose=0).ravel()\n",
        "#        best_th, best_f1 = 0.5, f1_score(y_val, (val_proba>=0.5).astype(int))\n",
        "#        for th in np.linspace(0.3, 0.7, 41):  # explora 0.30..0.70 cada 0.01\n",
        "#            f1v = f1_score(y_val, (val_proba>=th).astype(int))\n",
        "#            if f1v > best_f1:\n",
        "#                best_f1 = f1v\n",
        "#                best_th = th\n",
        "#\n",
        "#        # predecir test con ese threshold\n",
        "#        proba_test = model.predict(Xw_te_scaled, verbose=0).ravel()\n",
        "#        preds_test = (proba_test >= best_th).astype(int)\n",
        "#\n",
        "#        y_true_all.extend(yw_te.tolist())\n",
        "#        y_proba_all.extend(proba_test.tolist())\n",
        "#        y_pred_all.extend(preds_test.tolist())\n",
        "#\n",
        "#        start += step_size\n",
        "#\n",
        "#    # metrics globales\n",
        "#    from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "#    y_true_all = np.array(y_true_all)\n",
        "#    y_pred_all = np.array(y_pred_all)\n",
        "#    y_proba_all = np.array(y_proba_all)\n",
        "#\n",
        "#    metrics = {\n",
        "#        \"accuracy\": accuracy_score(y_true_all, y_pred_all),\n",
        "#        \"f1\": f1_score(y_true_all, y_pred_all),\n",
        "#        \"precision\": precision_score(y_true_all, y_pred_all),\n",
        "#        \"recall\": recall_score(y_true_all, y_pred_all),\n",
        "#        \"roc_auc\": roc_auc_score(y_true_all, y_proba_all)\n",
        "#    }\n",
        "#    return metrics\n",
        "#\n",
        "## -----------------------------\n",
        "## === EJECUCIÓN SOBRE df_bitcoin ===\n",
        "## -----------------------------\n",
        "## X = todas las columnas menos target\n",
        "#df_bitcoin[\"Open time\"] = pd.to_datetime(df_bitcoin[\"Open time\"])\n",
        "#df_bitcoin = df_bitcoin.set_index(\"Open time\")\n",
        "#\n",
        "#X_values = df_bitcoin.drop(columns=[\"Target\"]).values\n",
        "#y_values = df_bitcoin[\"Target\"].values\n",
        "#\n",
        "#\n",
        "#lookbacks = [14, 30, 60]\n",
        "#horizon = 1\n",
        "#train_size = 720\n",
        "#test_size = 30\n",
        "#step_size = 30\n",
        "#\n",
        "#results = []\n",
        "#\n",
        "#for lb in lookbacks:\n",
        "#    for model_name, builder in MODEL_BUILDERS_IMPROVED.items():\n",
        "#        print(f\"\\n>>> {model_name} | lookback={lb}\")\n",
        "#        metrics = walk_forward_with_threshold_tuning(\n",
        "#            X_values=X_values,\n",
        "#            y_values=y_values,\n",
        "#            window_size=lb,\n",
        "#            horizon=horizon,\n",
        "#            train_size=train_size,\n",
        "#            test_size=test_size,\n",
        "#            step_size=step_size,\n",
        "#            build_model_fn=builder,\n",
        "#            epochs=50,\n",
        "#            batch_size=64,\n",
        "#            val_frac_in_train=0.15,\n",
        "#            lr=1e-3,\n",
        "#            use_class_weights=True,\n",
        "#            verbose=1\n",
        "#        )\n",
        "#        results.append({\"model\": model_name, \"lookback\": lb, **metrics})\n",
        "#\n",
        "#results_df = pd.DataFrame(results).sort_values([\"roc_auc\",\"f1\",\"accuracy\"], ascending=False)\n",
        "#print(\"\\n=== RESULTADOS ===\")\n",
        "#print(results_df)"
      ],
      "metadata": {
        "id": "A0bVqkJ90XQe"
      },
      "id": "A0bVqkJ90XQe",
      "execution_count": 136,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}