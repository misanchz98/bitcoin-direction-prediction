{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misanchz98/bitcoin-direction-prediction/blob/main/03_modeling/03_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📊 Modelización con Redes Neuronales"
      ],
      "metadata": {
        "id": "oc3L8941w_7Q"
      },
      "id": "oc3L8941w_7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boruta"
      ],
      "metadata": {
        "id": "mOpTMtufuF3T",
        "outputId": "7f650abe-0511-495b-8656-bd47b596990b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mOpTMtufuF3T",
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boruta in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.12/dist-packages (from boruta) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from boruta) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from boruta) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.17.1->boruta) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.17.1->boruta) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LIBRERIAS\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, metrics\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Establecer el nivel de advertencias a \"ignore\" para ignorar todas las advertencias\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "PRb5hdMlxdH1"
      },
      "id": "PRb5hdMlxdH1",
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resetting the seeds for reproducibility\n",
        "def reset_random_seeds():\n",
        "    n = 1\n",
        "    os.environ['PYTHONHASHSEED'] = str(n)\n",
        "    tf.random.set_seed(n)\n",
        "    np.random.seed(n)\n",
        "    random.seed(n)\n",
        "\n",
        "reset_random_seeds()"
      ],
      "metadata": {
        "id": "AaKg9WJRg45w"
      },
      "id": "AaKg9WJRg45w",
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 1. Importación del conjunto de datos\n",
        "El primer paso consiste en cargar el conjunto de datos en nuestro entorno de trabajo. Estos datos están almacenados en un archivo CSV llamado `btc_historical_data_eda.csv`, cuya creación y obtención se explican en el notebook `02_data_analysis.ipynb`. Para ello, se utiliza el siguiente fragmento de código:"
      ],
      "metadata": {
        "id": "_zZmB5VkxQ8B"
      },
      "id": "_zZmB5VkxQ8B"
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos CSV\n",
        "url = 'https://raw.githubusercontent.com/misanchz98/bitcoin-direction-prediction/main/02_data_analysis/data/btc_historical_data_eda.csv'\n",
        "df_bitcoin = pd.read_csv(url, parse_dates=['Open time'])\n",
        "df_bitcoin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "orqWGSQqwZJw",
        "outputId": "13f8d398-ab39-4c92-f9c0-a1814a8245e7"
      },
      "id": "orqWGSQqwZJw",
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Open time      Close  Number of trades  Taker buy base asset volume  \\\n",
              "0    2017-10-05    4292.43            9158.0                   351.042019   \n",
              "1    2017-10-06    4369.00            6546.0                   226.148177   \n",
              "2    2017-10-07    4423.00            4804.0                   145.313076   \n",
              "3    2017-10-08    4640.00            7580.0                   280.094854   \n",
              "4    2017-10-09    4786.95           10372.0                   350.756559   \n",
              "...         ...        ...               ...                          ...   \n",
              "2872 2025-08-16  117380.66         1179842.0                  2995.228650   \n",
              "2873 2025-08-17  117405.01         1177563.0                  2804.731130   \n",
              "2874 2025-08-18  116227.05         3345487.0                  7647.218200   \n",
              "2875 2025-08-19  112872.94         3291170.0                  8609.360780   \n",
              "2876 2025-08-20  114271.24         2998370.0                  7209.585750   \n",
              "\n",
              "      Taker buy quote asset volume    Range   Candle  Target    CMF_20  \\\n",
              "0                     1.483037e+06   245.00    83.84       1  0.081329   \n",
              "1                     9.881066e+05   125.00    50.01       1  0.090972   \n",
              "2                     6.371469e+05   166.94    54.00       1  0.072898   \n",
              "3                     1.268661e+06   233.00   215.00       1  0.064115   \n",
              "4                     1.654275e+06   339.98   146.95       0  0.105281   \n",
              "...                            ...      ...      ...     ...       ...   \n",
              "2872                  3.521588e+08   755.01    38.62       1 -0.078079   \n",
              "2873                  3.307994e+08  1402.79    24.35       0 -0.071478   \n",
              "2874                  8.850528e+08  2903.61 -1177.96       0 -0.058026   \n",
              "2875                  9.840874e+08  3993.11 -3354.11       1 -0.133646   \n",
              "2876                  8.193310e+08  2235.38  1398.29       0 -0.048524   \n",
              "\n",
              "         MFI_14  ...  c2_ta_tendencia  c3_ta_tendencia  c1_ta_momentum  \\\n",
              "0     56.225018  ...         1.426309        -0.136861        1.317719   \n",
              "1     62.048701  ...         1.684975        -0.223654        1.843789   \n",
              "2     60.780168  ...         1.837639        -0.272101        1.714315   \n",
              "3     66.225272  ...         2.655718        -0.595153        4.539268   \n",
              "4     66.423592  ...         3.068594        -0.711866        4.065484   \n",
              "...         ...  ...              ...              ...             ...   \n",
              "2872  61.679789  ...        -2.974279        -0.597347       -1.738575   \n",
              "2873  61.441782  ...        -3.056170        -0.520901       -2.679964   \n",
              "2874  54.527915  ...        -3.371373        -0.335897       -3.708156   \n",
              "2875  53.037041  ...        -4.158761         0.112011       -5.328226   \n",
              "2876  47.355321  ...        -4.010127        -0.035153       -3.323554   \n",
              "\n",
              "      c2_ta_momentum  c3_ta_momentum  c4_ta_momentum  c5_ta_momentum  \\\n",
              "0          -0.126726       -1.676720        1.289633        0.019128   \n",
              "1          -0.313902       -0.766032        1.200655        0.108543   \n",
              "2           0.851111       -1.474281       -0.169404       -0.611932   \n",
              "3          -1.327677       -1.397994        0.344940        0.095779   \n",
              "4           0.284535       -0.496135       -0.373562       -0.383308   \n",
              "...              ...             ...             ...             ...   \n",
              "2872       -0.246759        0.045690        1.947962       -0.826190   \n",
              "2873        0.452454       -1.078307        1.833305       -0.382838   \n",
              "2874        1.216496       -0.767095        1.913662        1.633951   \n",
              "2875        0.713262        0.105456        1.232647       -1.954862   \n",
              "2876       -2.507455       -1.057876        1.180263       -1.303357   \n",
              "\n",
              "      c1_ta_volatilidad  c2_ta_volatilidad  c3_ta_volatilidad  \n",
              "0             -4.644643          -0.938175          -0.259897  \n",
              "1             -4.656021          -1.404483          -0.298095  \n",
              "2             -4.658149          -1.694457          -0.310605  \n",
              "3             -4.643444          -2.930102          -0.299058  \n",
              "4             -4.619178          -3.116037          -0.259659  \n",
              "...                 ...                ...                ...  \n",
              "2872          11.130802           0.715864          -3.617415  \n",
              "2873          11.062656           0.708259          -3.717682  \n",
              "2874          11.085307           1.427748          -3.651715  \n",
              "2875          11.229262           3.161925          -3.269720  \n",
              "2876          11.207456           2.153090          -3.227203  \n",
              "\n",
              "[2877 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2aae7e15-691e-4cbb-a47c-9d53f1279f69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open time</th>\n",
              "      <th>Close</th>\n",
              "      <th>Number of trades</th>\n",
              "      <th>Taker buy base asset volume</th>\n",
              "      <th>Taker buy quote asset volume</th>\n",
              "      <th>Range</th>\n",
              "      <th>Candle</th>\n",
              "      <th>Target</th>\n",
              "      <th>CMF_20</th>\n",
              "      <th>MFI_14</th>\n",
              "      <th>...</th>\n",
              "      <th>c2_ta_tendencia</th>\n",
              "      <th>c3_ta_tendencia</th>\n",
              "      <th>c1_ta_momentum</th>\n",
              "      <th>c2_ta_momentum</th>\n",
              "      <th>c3_ta_momentum</th>\n",
              "      <th>c4_ta_momentum</th>\n",
              "      <th>c5_ta_momentum</th>\n",
              "      <th>c1_ta_volatilidad</th>\n",
              "      <th>c2_ta_volatilidad</th>\n",
              "      <th>c3_ta_volatilidad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-10-05</td>\n",
              "      <td>4292.43</td>\n",
              "      <td>9158.0</td>\n",
              "      <td>351.042019</td>\n",
              "      <td>1.483037e+06</td>\n",
              "      <td>245.00</td>\n",
              "      <td>83.84</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081329</td>\n",
              "      <td>56.225018</td>\n",
              "      <td>...</td>\n",
              "      <td>1.426309</td>\n",
              "      <td>-0.136861</td>\n",
              "      <td>1.317719</td>\n",
              "      <td>-0.126726</td>\n",
              "      <td>-1.676720</td>\n",
              "      <td>1.289633</td>\n",
              "      <td>0.019128</td>\n",
              "      <td>-4.644643</td>\n",
              "      <td>-0.938175</td>\n",
              "      <td>-0.259897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-10-06</td>\n",
              "      <td>4369.00</td>\n",
              "      <td>6546.0</td>\n",
              "      <td>226.148177</td>\n",
              "      <td>9.881066e+05</td>\n",
              "      <td>125.00</td>\n",
              "      <td>50.01</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090972</td>\n",
              "      <td>62.048701</td>\n",
              "      <td>...</td>\n",
              "      <td>1.684975</td>\n",
              "      <td>-0.223654</td>\n",
              "      <td>1.843789</td>\n",
              "      <td>-0.313902</td>\n",
              "      <td>-0.766032</td>\n",
              "      <td>1.200655</td>\n",
              "      <td>0.108543</td>\n",
              "      <td>-4.656021</td>\n",
              "      <td>-1.404483</td>\n",
              "      <td>-0.298095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-10-07</td>\n",
              "      <td>4423.00</td>\n",
              "      <td>4804.0</td>\n",
              "      <td>145.313076</td>\n",
              "      <td>6.371469e+05</td>\n",
              "      <td>166.94</td>\n",
              "      <td>54.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.072898</td>\n",
              "      <td>60.780168</td>\n",
              "      <td>...</td>\n",
              "      <td>1.837639</td>\n",
              "      <td>-0.272101</td>\n",
              "      <td>1.714315</td>\n",
              "      <td>0.851111</td>\n",
              "      <td>-1.474281</td>\n",
              "      <td>-0.169404</td>\n",
              "      <td>-0.611932</td>\n",
              "      <td>-4.658149</td>\n",
              "      <td>-1.694457</td>\n",
              "      <td>-0.310605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-10-08</td>\n",
              "      <td>4640.00</td>\n",
              "      <td>7580.0</td>\n",
              "      <td>280.094854</td>\n",
              "      <td>1.268661e+06</td>\n",
              "      <td>233.00</td>\n",
              "      <td>215.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.064115</td>\n",
              "      <td>66.225272</td>\n",
              "      <td>...</td>\n",
              "      <td>2.655718</td>\n",
              "      <td>-0.595153</td>\n",
              "      <td>4.539268</td>\n",
              "      <td>-1.327677</td>\n",
              "      <td>-1.397994</td>\n",
              "      <td>0.344940</td>\n",
              "      <td>0.095779</td>\n",
              "      <td>-4.643444</td>\n",
              "      <td>-2.930102</td>\n",
              "      <td>-0.299058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-10-09</td>\n",
              "      <td>4786.95</td>\n",
              "      <td>10372.0</td>\n",
              "      <td>350.756559</td>\n",
              "      <td>1.654275e+06</td>\n",
              "      <td>339.98</td>\n",
              "      <td>146.95</td>\n",
              "      <td>0</td>\n",
              "      <td>0.105281</td>\n",
              "      <td>66.423592</td>\n",
              "      <td>...</td>\n",
              "      <td>3.068594</td>\n",
              "      <td>-0.711866</td>\n",
              "      <td>4.065484</td>\n",
              "      <td>0.284535</td>\n",
              "      <td>-0.496135</td>\n",
              "      <td>-0.373562</td>\n",
              "      <td>-0.383308</td>\n",
              "      <td>-4.619178</td>\n",
              "      <td>-3.116037</td>\n",
              "      <td>-0.259659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2872</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>117380.66</td>\n",
              "      <td>1179842.0</td>\n",
              "      <td>2995.228650</td>\n",
              "      <td>3.521588e+08</td>\n",
              "      <td>755.01</td>\n",
              "      <td>38.62</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.078079</td>\n",
              "      <td>61.679789</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.974279</td>\n",
              "      <td>-0.597347</td>\n",
              "      <td>-1.738575</td>\n",
              "      <td>-0.246759</td>\n",
              "      <td>0.045690</td>\n",
              "      <td>1.947962</td>\n",
              "      <td>-0.826190</td>\n",
              "      <td>11.130802</td>\n",
              "      <td>0.715864</td>\n",
              "      <td>-3.617415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2873</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>117405.01</td>\n",
              "      <td>1177563.0</td>\n",
              "      <td>2804.731130</td>\n",
              "      <td>3.307994e+08</td>\n",
              "      <td>1402.79</td>\n",
              "      <td>24.35</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.071478</td>\n",
              "      <td>61.441782</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.056170</td>\n",
              "      <td>-0.520901</td>\n",
              "      <td>-2.679964</td>\n",
              "      <td>0.452454</td>\n",
              "      <td>-1.078307</td>\n",
              "      <td>1.833305</td>\n",
              "      <td>-0.382838</td>\n",
              "      <td>11.062656</td>\n",
              "      <td>0.708259</td>\n",
              "      <td>-3.717682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2874</th>\n",
              "      <td>2025-08-18</td>\n",
              "      <td>116227.05</td>\n",
              "      <td>3345487.0</td>\n",
              "      <td>7647.218200</td>\n",
              "      <td>8.850528e+08</td>\n",
              "      <td>2903.61</td>\n",
              "      <td>-1177.96</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.058026</td>\n",
              "      <td>54.527915</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.371373</td>\n",
              "      <td>-0.335897</td>\n",
              "      <td>-3.708156</td>\n",
              "      <td>1.216496</td>\n",
              "      <td>-0.767095</td>\n",
              "      <td>1.913662</td>\n",
              "      <td>1.633951</td>\n",
              "      <td>11.085307</td>\n",
              "      <td>1.427748</td>\n",
              "      <td>-3.651715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2875</th>\n",
              "      <td>2025-08-19</td>\n",
              "      <td>112872.94</td>\n",
              "      <td>3291170.0</td>\n",
              "      <td>8609.360780</td>\n",
              "      <td>9.840874e+08</td>\n",
              "      <td>3993.11</td>\n",
              "      <td>-3354.11</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.133646</td>\n",
              "      <td>53.037041</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.158761</td>\n",
              "      <td>0.112011</td>\n",
              "      <td>-5.328226</td>\n",
              "      <td>0.713262</td>\n",
              "      <td>0.105456</td>\n",
              "      <td>1.232647</td>\n",
              "      <td>-1.954862</td>\n",
              "      <td>11.229262</td>\n",
              "      <td>3.161925</td>\n",
              "      <td>-3.269720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>2025-08-20</td>\n",
              "      <td>114271.24</td>\n",
              "      <td>2998370.0</td>\n",
              "      <td>7209.585750</td>\n",
              "      <td>8.193310e+08</td>\n",
              "      <td>2235.38</td>\n",
              "      <td>1398.29</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.048524</td>\n",
              "      <td>47.355321</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.010127</td>\n",
              "      <td>-0.035153</td>\n",
              "      <td>-3.323554</td>\n",
              "      <td>-2.507455</td>\n",
              "      <td>-1.057876</td>\n",
              "      <td>1.180263</td>\n",
              "      <td>-1.303357</td>\n",
              "      <td>11.207456</td>\n",
              "      <td>2.153090</td>\n",
              "      <td>-3.227203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2877 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aae7e15-691e-4cbb-a47c-9d53f1279f69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2aae7e15-691e-4cbb-a47c-9d53f1279f69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2aae7e15-691e-4cbb-a47c-9d53f1279f69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_bitcoin"
            }
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 2. División del conjunto de datos"
      ],
      "metadata": {
        "id": "gpxUhj2LfI3z"
      },
      "id": "gpxUhj2LfI3z"
    },
    {
      "cell_type": "code",
      "source": [
        "#X = df_bitcoin.drop(['Open time', 'Target'], axis=1)\n",
        "#y = df_bitcoin['Target']\n",
        "#\n",
        "## separate training data from testing data\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "#\n",
        "## scale the input data\n",
        "#scaler = StandardScaler()\n",
        "#\n",
        "## Reshape X_train and X_test if they are 1D\n",
        "#if X_train.ndim == 1:\n",
        "#    X_train = X_train.to_numpy().reshape(-1, 1)\n",
        "#if X_test.ndim == 1:\n",
        "#    X_test = X_test.to_numpy().reshape(-1, 1)\n",
        "#\n",
        "#X_train_scaled = scaler.fit_transform(X_train)\n",
        "#X_test_scaled = scaler.transform(X_test)\n",
        "#\n",
        "## reshape the input data for CNN-LSTM (samples, timesteps, features)\n",
        "#def create_sequences(data, timesteps):\n",
        "#    X = []\n",
        "#    for i in range(len(data) - timesteps + 1):\n",
        "#        X.append(data[i:i + timesteps])\n",
        "#    return np.array(X)\n",
        "#\n",
        "#timesteps = 30\n",
        "#X_train_reshaped = create_sequences(X_train_scaled, timesteps)\n",
        "#X_test_reshaped = create_sequences(X_test_scaled, timesteps)\n",
        "#y_train = y_train[timesteps - 1:]\n",
        "#y_test = y_test[timesteps - 1:]"
      ],
      "metadata": {
        "id": "rtEjAgeufewH"
      },
      "id": "rtEjAgeufewH",
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Separar validación temporal (último 10%)\n",
        "# ---------------------------\n",
        "#val_size = int(0.1 * len(X_train_reshaped))  # usa 10% final como validación\n",
        "#X_train, X_val = X_train_reshaped[:-val_size], X_train_reshaped[-val_size:]\n",
        "#y_train_split, y_val = y_train[:-val_size], y_train[-val_size:]"
      ],
      "metadata": {
        "id": "03haV9xuNQvO"
      },
      "id": "03haV9xuNQvO",
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Umbral"
      ],
      "metadata": {
        "id": "nIKbv2-kNDcp"
      },
      "id": "nIKbv2-kNDcp"
    },
    {
      "cell_type": "code",
      "source": [
        "#def find_best_threshold(y_true, y_probs):\n",
        "#    thresholds = np.linspace(0, 1, 101)  # de 0.00 a 1.00 en pasos de 0.01\n",
        "#    f1_scores = []\n",
        "#\n",
        "#    for t in thresholds:\n",
        "#        y_pred = (y_probs >= t).astype(int)\n",
        "#        f1 = f1_score(y_true, y_pred)\n",
        "#        f1_scores.append(f1)\n",
        "#\n",
        "#    best_idx = np.argmax(f1_scores)\n",
        "#    return thresholds[best_idx], f1_scores[best_idx], thresholds, f1_scores"
      ],
      "metadata": {
        "id": "3PwdY4rTNF6b"
      },
      "id": "3PwdY4rTNF6b",
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "ENlCQ09tmahV"
      },
      "id": "ENlCQ09tmahV"
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras import backend as K\n",
        "#\n",
        "#def f1_score_2(y_true, y_pred):\n",
        "#    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "#    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "#    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "#    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "#    recall = true_positives / (possible_positives + K.epsilon())\n",
        "#    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "#    return f1_val"
      ],
      "metadata": {
        "id": "_rBNXkQCsz8S"
      },
      "id": "_rBNXkQCsz8S",
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "\n",
        "#model = Sequential()\n",
        "#model.add(LSTM(256, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(128, return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(64))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dense(1, activation='sigmoid'))  # binaria\n",
        "#\n",
        "#model.compile(\n",
        "#    optimizer=Adam(learning_rate=0.001),\n",
        "#    loss='binary_crossentropy',\n",
        "#    metrics=[metrics.BinaryAccuracy(), metrics.Precision(), metrics.Recall(), f1_score_2]\n",
        "#)\n",
        "#\n",
        "#early_stopping = EarlyStopping(\n",
        "#    monitor='val_binary_accuracy',  # mejor usar val_binary_accuracy\n",
        "#    patience=50,\n",
        "#    mode='max',\n",
        "#    restore_best_weights=True\n",
        "#)\n",
        "#\n",
        "#history = model.fit(\n",
        "#    X_train_reshaped, y_train.astype('float32'),  # convertir a float32\n",
        "#    epochs=100,\n",
        "#    batch_size=50,\n",
        "#    validation_split=0.1,\n",
        "#    callbacks=[early_stopping]\n",
        "#)\n",
        "#"
      ],
      "metadata": {
        "id": "jheEAEKQs72Y"
      },
      "id": "jheEAEKQs72Y",
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#from sklearn.metrics import f1_score\n",
        "#from tensorflow.keras import Sequential, metrics\n",
        "#from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "#\n",
        "## ---------------------------\n",
        "## Callback para calcular F1 global en validación\n",
        "## ---------------------------\n",
        "#class F1Callback(Callback):\n",
        "#    def __init__(self, validation_data):\n",
        "#        super().__init__()\n",
        "#        self.validation_data = validation_data\n",
        "#        self.f1_scores = []\n",
        "#\n",
        "#    def on_epoch_end(self, epoch, logs=None):\n",
        "#        X_val, y_val = self.validation_data\n",
        "#        y_pred = (self.model.predict(X_val, verbose=0) > 0.5).astype(\"int32\")\n",
        "#        f1 = f1_score(y_val, y_pred)\n",
        "#        self.f1_scores.append(f1)\n",
        "#        print(f\" — val_f1: {f1:.4f}\")\n",
        "#        logs[\"val_f1\"] = f1  # se guarda para que EarlyStopping lo pueda monitorizar\n",
        "#\n",
        "#\n",
        "## ---------------------------\n",
        "## Modelo LSTM\n",
        "## ---------------------------\n",
        "#model = Sequential()\n",
        "#model.add(LSTM(256, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(128, return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(64))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dense(1, activation='sigmoid'))  # binaria\n",
        "#\n",
        "#\n",
        "## ---------------------------\n",
        "## Compilación\n",
        "## ---------------------------\n",
        "#model.compile(\n",
        "#    optimizer=Adam(learning_rate=0.001),\n",
        "#    loss='binary_crossentropy',\n",
        "#    metrics=[\n",
        "#        metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "#        metrics.Precision(name=\"precision\"),\n",
        "#        metrics.Recall(name=\"recall\"),\n",
        "#        tf.keras.metrics.AUC(curve=\"PR\", name=\"auc_pr\")\n",
        "#    ]\n",
        "#)\n",
        "#\n",
        "## ---------------------------\n",
        "## Callbacks\n",
        "## ---------------------------\n",
        "#f1_callback = F1Callback(validation_data=(X_val, y_val))\n",
        "#\n",
        "#early_stopping = EarlyStopping(\n",
        "#    monitor='val_f1',   # ahora se detiene según F1\n",
        "#    patience=30,\n",
        "#    mode='max',\n",
        "#    restore_best_weights=True\n",
        "#)\n",
        "#\n",
        "## ---------------------------\n",
        "## Entrenamiento\n",
        "## ---------------------------\n",
        "#history = model.fit(\n",
        "#    X_train, y_train_split.astype('float32'),\n",
        "#    epochs=100,\n",
        "#    batch_size=50,\n",
        "#    validation_data=(X_val, y_val.astype('float32')),\n",
        "#    callbacks=[early_stopping, f1_callback],\n",
        "#    shuffle=False   # MUY IMPORTANTE en series temporales\n",
        "#)\n",
        "#"
      ],
      "metadata": {
        "id": "DPB7hjLwJphQ"
      },
      "id": "DPB7hjLwJphQ",
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from tensorflow.keras import Sequential, metrics\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------------\n",
        "# PREPARACIÓN DE DATOS MEJORADA\n",
        "# ---------------------------\n",
        "\n",
        "X = df_bitcoin.drop(['Open time', 'Target'], axis=1)\n",
        "y = df_bitcoin['Target']\n",
        "\n",
        "print(f\"📊 Dataset info:\")\n",
        "print(f\"   • Total samples: {len(X)}\")\n",
        "print(f\"   • Features: {X.shape[1]}\")\n",
        "print(f\"   • Positive class: {y.sum()} ({y.mean():.2%})\")\n",
        "\n",
        "# Separate training data from testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "By55Fbekpmou",
        "outputId": "dee2eddf-5883-44d2-cd5b-d7df71fed375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "By55Fbekpmou",
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Dataset info:\n",
            "   • Total samples: 2877\n",
            "   • Features: 42\n",
            "   • Positive class: 1482 (51.51%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Entrenar el modelo RandomForestClassifier con todo el conjunto de datos\n",
        "model1 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Obtener las importancias de las características\n",
        "importances = model1.feature_importances_\n",
        "\n",
        "# Crear un DataFrame con las características y sus importancias\n",
        "features = X_train.columns\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Ordenar las características por importancia de mayor a menor\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Mostrar las 10 variables más importantes\n",
        "print(\"\\nLas 10 variables más importantes según Random Forest:\")\n",
        "print(feature_importance_df.head(25))\n",
        "\n",
        "top_10_feature = feature_importance_df['Feature'].head(25).tolist()\n",
        "#X_train = X_train[top_10_feature]\n",
        "#X_test = X_test[top_10_feature]"
      ],
      "metadata": {
        "id": "FaDWWjZnqp7h",
        "outputId": "71c9325a-ec89-4777-fc59-965f5adc7d0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FaDWWjZnqp7h",
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Las 10 variables más importantes según Random Forest:\n",
            "                      Feature  Importance\n",
            "13                   CMF_diff    0.028962\n",
            "17                   ADL_diff    0.028097\n",
            "15                   MFI_diff    0.027379\n",
            "9                    OBV_diff    0.026997\n",
            "14                 CMF_zscore    0.026641\n",
            "35             c2_ta_momentum    0.026617\n",
            "38             c5_ta_momentum    0.026389\n",
            "30     total_transaction_fees    0.026138\n",
            "6                      CMF_20    0.025887\n",
            "36             c3_ta_momentum    0.025790\n",
            "23               mempool_size    0.025406\n",
            "16                 MFI_zscore    0.025284\n",
            "7                      MFI_14    0.025130\n",
            "27  average_confirmation_time    0.024765\n",
            "37             c4_ta_momentum    0.024572\n",
            "32            c2_ta_tendencia    0.024481\n",
            "18                  ADL_roc_5    0.024213\n",
            "10                  OBV_roc_5    0.024154\n",
            "25         average_block_size    0.024016\n",
            "22             diff_Vol_ratio    0.023724\n",
            "5                      Candle    0.023443\n",
            "20               Vol_ratio_50    0.023311\n",
            "11                   OBV_ma20    0.023249\n",
            "33            c3_ta_tendencia    0.023202\n",
            "29             miners_revenue    0.023152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# define random forest classifier, with utilising all cores and\n",
        "# sampling in proportion to y labels\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "# define Boruta feature selection method\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
        "\n",
        "# find all relevant features\n",
        "feat_selector.fit(X_train, y_train)\n",
        "\n",
        "# --- Nombres de features ---\n",
        "features = np.array(X_train.columns)\n",
        "\n",
        "# --- Features confirmadas ---\n",
        "confirmed_features = features[feat_selector.support_]\n",
        "print(\"Confirmed features:\", confirmed_features)\n",
        "\n",
        "# --- Features tentativas ---\n",
        "tentative_mask = feat_selector.support_weak_  # Boruta marca las tentativas con support_weak_\n",
        "tentative_features = features[tentative_mask]\n",
        "print(\"Tentative features:\", tentative_features)\n",
        "\n",
        "# --- (Opcional) Todas las features con su ranking ---\n",
        "feature_rankings = feat_selector.ranking_\n",
        "df_features = pd.DataFrame({\n",
        "    'feature': features,\n",
        "    'ranking': feature_rankings\n",
        "}).sort_values(by='ranking')\n",
        "print(df_features)"
      ],
      "metadata": {
        "id": "VlunphmGt0df",
        "outputId": "fef414c0-cc7e-489e-b9d4-eb8af8517a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VlunphmGt0df",
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t42\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t42\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t42\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t42\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t42\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t42\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t42\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t9\n",
            "Rejected: \t33\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t7\n",
            "Rejected: \t33\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t6\n",
            "Rejected: \t34\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t2\n",
            "Tentative: \t5\n",
            "Rejected: \t35\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t3\n",
            "Tentative: \t4\n",
            "Rejected: \t35\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t4\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Confirmed features: ['OBV_diff' 'ADL_diff' 'miners_revenue' 'total_transaction_fees']\n",
            "Tentative features: ['Close' 'c1_ta_momentum']\n",
            "                         feature  ranking\n",
            "9                       OBV_diff        1\n",
            "29                miners_revenue        1\n",
            "30        total_transaction_fees        1\n",
            "17                      ADL_diff        1\n",
            "0                          Close        2\n",
            "34                c1_ta_momentum        2\n",
            "5                         Candle        3\n",
            "15                      MFI_diff        4\n",
            "13                      CMF_diff        5\n",
            "35                c2_ta_momentum        6\n",
            "33               c3_ta_tendencia        7\n",
            "20                  Vol_ratio_50        8\n",
            "8                            ADL        8\n",
            "38                c5_ta_momentum       10\n",
            "31               c1_ta_tendencia       10\n",
            "14                    CMF_zscore       12\n",
            "32               c2_ta_tendencia       12\n",
            "28                     hash_rate       14\n",
            "19                     Vol_SMA20       14\n",
            "3   Taker buy quote asset volume       16\n",
            "40             c2_ta_volatilidad       17\n",
            "39             c1_ta_volatilidad       18\n",
            "2    Taker buy base asset volume       19\n",
            "1               Number of trades       19\n",
            "16                    MFI_zscore       21\n",
            "11                      OBV_ma20       21\n",
            "27     average_confirmation_time       23\n",
            "10                     OBV_roc_5       24\n",
            "6                         CMF_20       25\n",
            "36                c3_ta_momentum       26\n",
            "7                         MFI_14       27\n",
            "18                     ADL_roc_5       28\n",
            "21                  diff_Vol_SMA       29\n",
            "23                  mempool_size       30\n",
            "25            average_block_size       31\n",
            "37                c4_ta_momentum       32\n",
            "22                diff_Vol_ratio       32\n",
            "12                  OBV_ma_cross       34\n",
            "4                          Range       35\n",
            "41             c3_ta_volatilidad       36\n",
            "24              transaction_rate       37\n",
            "26           exchange_volume_usd       38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the input data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Reshape X_train and X_test if they are 1D\n",
        "if X_train.ndim == 1:\n",
        "    X_train = X_train.to_numpy().reshape(-1, 1)\n",
        "if X_test.ndim == 1:\n",
        "    X_test = X_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# FUNCIÓN MEJORADA PARA SECUENCIAS\n",
        "# ---------------------------\n",
        "\n",
        "def create_sequences_improved(data, targets, timesteps, stride=1):\n",
        "    \"\"\"\n",
        "    Crea secuencias con opción de stride para reducir correlación\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(0, len(data) - timesteps + 1, stride):\n",
        "        X.append(data[i:i + timesteps])\n",
        "        y.append(targets[i + timesteps - 1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# CAMBIO IMPORTANTE: Reducir timesteps y usar stride\n",
        "timesteps = 20  # Reducido de 30 para evitar sobreajuste\n",
        "stride = 2      # Añadido stride para reducir correlación entre muestras\n",
        "\n",
        "print(f\"🔧 Creando secuencias temporales:\")\n",
        "print(f\"   • Timesteps: {timesteps}\")\n",
        "print(f\"   • Stride: {stride}\")\n",
        "\n",
        "X_train_reshaped, y_train_adj = create_sequences_improved(X_train_scaled, y_train.values, timesteps, stride)\n",
        "X_test_reshaped, y_test_adj = create_sequences_improved(X_test_scaled, y_test.values, timesteps, stride)\n",
        "\n",
        "print(f\"   • Train sequences: {X_train_reshaped.shape}\")\n",
        "print(f\"   • Test sequences: {X_test_reshaped.shape}\")\n",
        "\n",
        "# ---------------------------\n",
        "# DIVISIÓN TEMPORAL ESTRICTA PARA VALIDACIÓN\n",
        "# ---------------------------\n",
        "\n",
        "# CAMBIO: Usar división temporal más estricta\n",
        "val_size = int(0.15 * len(X_train_reshaped))  # Aumentado a 15%\n",
        "\n",
        "# Separación temporal estricta\n",
        "X_train_final = X_train_reshaped[:-val_size]\n",
        "X_val = X_train_reshaped[-val_size:]\n",
        "y_train_final = y_train_adj[:-val_size]\n",
        "y_val = y_train_adj[-val_size:]\n",
        "\n",
        "print(f\"📊 Conjuntos finales:\")\n",
        "print(f\"   • Train: {X_train_final.shape[0]} samples\")\n",
        "print(f\"   • Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"   • Test: {X_test_reshaped.shape[0]} samples\")\n",
        "\n",
        "# Verificar distribución de clases\n",
        "print(f\"\\n📈 Distribución de clases:\")\n",
        "print(f\"   • Train: {np.bincount(y_train_final)} ({np.mean(y_train_final):.2%} positive)\")\n",
        "print(f\"   • Validation: {np.bincount(y_val)} ({np.mean(y_val):.2%} positive)\")\n",
        "print(f\"   • Test: {np.bincount(y_test_adj)} ({np.mean(y_test_adj):.2%} positive)\")\n",
        "\n",
        "# ---------------------------\n",
        "# CALLBACK MEJORADO CON MONITOREO AVANZADO\n",
        "# ---------------------------\n",
        "\n",
        "class AdvancedF1Callback(Callback):\n",
        "    def __init__(self, validation_data, train_sample_data=None):\n",
        "        super().__init__()\n",
        "        self.validation_data = validation_data\n",
        "        self.train_sample_data = train_sample_data\n",
        "        self.val_f1_scores = []\n",
        "        self.train_f1_scores = []\n",
        "        self.overfitting_alerts = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        X_val, y_val = self.validation_data\n",
        "        y_pred_val = (self.model.predict(X_val, verbose=0) > 0.5).astype(\"int32\")\n",
        "        f1_val = f1_score(y_val, y_pred_val, zero_division=0)\n",
        "        self.val_f1_scores.append(f1_val)\n",
        "\n",
        "        # Calcular F1 en muestra de entrenamiento para detectar sobreajuste\n",
        "        if self.train_sample_data is not None:\n",
        "            X_train_sample, y_train_sample = self.train_sample_data\n",
        "            y_pred_train = (self.model.predict(X_train_sample, verbose=0) > 0.5).astype(\"int32\")\n",
        "            f1_train = f1_score(y_train_sample, y_pred_train, zero_division=0)\n",
        "            self.train_f1_scores.append(f1_train)\n",
        "\n",
        "            # Detectar sobreajuste\n",
        "            overfitting_gap = f1_train - f1_val\n",
        "            if overfitting_gap > 0.3:\n",
        "                self.overfitting_alerts.append(epoch)\n",
        "                print(f\" — 🚨 OVERFITTING ALERT: gap={overfitting_gap:.3f}\")\n",
        "\n",
        "            print(f\" — train_f1: {f1_train:.4f} — val_f1: {f1_val:.4f} — gap: {overfitting_gap:+.3f}\")\n",
        "        else:\n",
        "            print(f\" — val_f1: {f1_val:.4f}\")\n",
        "\n",
        "        logs[\"val_f1\"] = f1_val\n",
        "\n",
        "# ---------------------------\n",
        "# MODELO ANTI-SOBREAJUSTE\n",
        "# ---------------------------\n",
        "\n",
        "def create_anti_overfitting_model(input_shape, complexity_level='moderate'):\n",
        "    \"\"\"\n",
        "    Crea modelo con diferentes niveles de complejidad\n",
        "    \"\"\"\n",
        "\n",
        "    if complexity_level == 'minimal':\n",
        "        print(\"🏗️  Creando modelo MINIMAL...\")\n",
        "        model = Sequential([\n",
        "            LSTM(32, input_shape=input_shape, dropout=0.5, recurrent_dropout=0.3),\n",
        "            Dropout(0.5),\n",
        "            Dense(16, activation='relu', kernel_regularizer=l1_l2(l2=0.01)),\n",
        "            Dropout(0.4),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    elif complexity_level == 'moderate':\n",
        "        print(\"🏗️  Creando modelo MODERADO...\")\n",
        "        model = Sequential([\n",
        "            # Primera LSTM más pequeña\n",
        "            LSTM(64, return_sequences=True, input_shape=input_shape,\n",
        "                 dropout=0.4, recurrent_dropout=0.2,\n",
        "                 kernel_regularizer=l1_l2(l2=0.001)),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # Segunda LSTM aún más pequeña\n",
        "            LSTM(32, dropout=0.4, recurrent_dropout=0.2,\n",
        "                 kernel_regularizer=l1_l2(l2=0.001)),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            # Capas densas pequeñas\n",
        "            Dense(24, activation='relu', kernel_regularizer=l1_l2(l2=0.001)),\n",
        "            Dropout(0.5),\n",
        "            Dense(8, activation='relu'),\n",
        "            Dropout(0.3),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    else:  # conservative\n",
        "        print(\"🏗️  Creando modelo CONSERVADOR...\")\n",
        "        model = Sequential([\n",
        "            LSTM(48, return_sequences=True, input_shape=input_shape,\n",
        "                 dropout=0.5, recurrent_dropout=0.3,\n",
        "                 kernel_regularizer=l1_l2(l2=0.01)),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            LSTM(24, dropout=0.5, recurrent_dropout=0.3,\n",
        "                 kernel_regularizer=l1_l2(l2=0.01)),\n",
        "            BatchNormalization(),\n",
        "\n",
        "            Dense(16, activation='relu', kernel_regularizer=l1_l2(l2=0.01)),\n",
        "            Dropout(0.6),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear modelo (empezar con moderate, cambiar a minimal si hay sobreajuste)\n",
        "model = create_anti_overfitting_model(\n",
        "    input_shape=(X_train_final.shape[1], X_train_final.shape[2]),\n",
        "    complexity_level='moderate'\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# COMPILACIÓN MEJORADA\n",
        "# ---------------------------\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),  # Learning rate más conservador\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "        metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "        metrics.Precision(name=\"precision\"),\n",
        "        metrics.Recall(name=\"recall\"),\n",
        "        metrics.AUC(curve=\"PR\", name=\"auc_pr\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\n📋 ARQUITECTURA DEL MODELO:\")\n",
        "model.summary()\n",
        "\n",
        "# ---------------------------\n",
        "# CALLBACKS AVANZADOS\n",
        "# ---------------------------\n",
        "\n",
        "# Muestra de entrenamiento para monitoreo\n",
        "train_sample_size = min(2000, len(X_train_final))\n",
        "train_sample_indices = np.random.choice(len(X_train_final), train_sample_size, replace=False)\n",
        "train_sample_data = (X_train_final[train_sample_indices], y_train_final[train_sample_indices])\n",
        "\n",
        "f1_callback = AdvancedF1Callback(\n",
        "    validation_data=(X_val, y_val),\n",
        "    train_sample_data=train_sample_data\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Más estable que val_f1\n",
        "    patience=15,         # Reducido para evitar sobreajuste\n",
        "    mode='min',\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=8,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# ENTRENAMIENTO CONSERVADOR\n",
        "# ---------------------------\n",
        "\n",
        "print(f\"\\n🎯 INICIANDO ENTRENAMIENTO:\")\n",
        "print(f\"   • Épocas máximas: 60 (reducido)\")\n",
        "print(f\"   • Batch size: 64 (aumentado)\")\n",
        "print(f\"   • Learning rate: 0.0005 (reducido)\")\n",
        "print(f\"   • Early stopping patience: 15\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_final, y_train_final.astype('float32'),\n",
        "    epochs=60,           # Reducido de 100\n",
        "    batch_size=64,       # Aumentado de 50 para mejor generalización\n",
        "    validation_data=(X_val, y_val.astype('float32')),\n",
        "    callbacks=[early_stopping, reduce_lr, f1_callback],\n",
        "    shuffle=False,       # Mantener orden temporal\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# ANÁLISIS POST-ENTRENAMIENTO\n",
        "# ---------------------------\n",
        "\n",
        "def plot_training_analysis(history, f1_callback):\n",
        "    \"\"\"\n",
        "    Análisis visual del entrenamiento\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Loss\n",
        "    axes[0,0].plot(history.history['loss'], label='Train Loss', alpha=0.8)\n",
        "    axes[0,0].plot(history.history['val_loss'], label='Val Loss', alpha=0.8)\n",
        "    axes[0,0].set_title('Loss Evolution')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0,1].plot(history.history['accuracy'], label='Train Acc', alpha=0.8)\n",
        "    axes[0,1].plot(history.history['val_accuracy'], label='Val Acc', alpha=0.8)\n",
        "    axes[0,1].set_title('Accuracy Evolution')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 Scores\n",
        "    if hasattr(f1_callback, 'train_f1_scores') and f1_callback.train_f1_scores:\n",
        "        axes[1,0].plot(f1_callback.train_f1_scores, label='Train F1', alpha=0.8)\n",
        "    axes[1,0].plot(f1_callback.val_f1_scores, label='Val F1', alpha=0.8)\n",
        "    axes[1,0].set_title('F1-Score Evolution')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Overfitting alerts\n",
        "    if f1_callback.overfitting_alerts:\n",
        "        axes[1,1].scatter(f1_callback.overfitting_alerts,\n",
        "                         [1]*len(f1_callback.overfitting_alerts),\n",
        "                         color='red', s=100, alpha=0.7)\n",
        "        axes[1,1].set_title(f'Overfitting Alerts: {len(f1_callback.overfitting_alerts)}')\n",
        "    else:\n",
        "        axes[1,1].text(0.5, 0.5, 'No Overfitting\\nAlerts',\n",
        "                      ha='center', va='center', transform=axes[1,1].transAxes,\n",
        "                      fontsize=14, color='green')\n",
        "        axes[1,1].set_title('Overfitting Status: ✅ CLEAN')\n",
        "\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_final_performance(model, X_train, y_train, X_val, y_val, X_test, y_test, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evaluación completa del rendimiento\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EVALUACIÓN FINAL DEL MODELO MEJORADO\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Usar muestra de train para evaluación\n",
        "    train_sample_size = min(3000, len(X_train))\n",
        "    train_indices = np.random.choice(len(X_train), train_sample_size, replace=False)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred_train = (model.predict(X_train[train_indices], verbose=0) > threshold).astype(int)\n",
        "    y_pred_val = (model.predict(X_val, verbose=0) > threshold).astype(int)\n",
        "    y_pred_test = (model.predict(X_test, verbose=0) > threshold).astype(int)\n",
        "\n",
        "    # Calcular métricas\n",
        "    datasets = ['Train (sample)', 'Validation', 'Test']\n",
        "    y_true_sets = [y_train[train_indices], y_val, y_test]\n",
        "    y_pred_sets = [y_pred_train, y_pred_val, y_pred_test]\n",
        "\n",
        "    results = {}\n",
        "    print(f\"{'Dataset':<15} {'Accuracy':<9} {'Precision':<10} {'Recall':<9} {'F1-Score':<9}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for dataset, y_true, y_pred in zip(datasets, y_true_sets, y_pred_sets):\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "        results[dataset] = {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
        "        print(f\"{dataset:<15} {acc:.4f}    {prec:.4f}     {rec:.4f}    {f1:.4f}\")\n",
        "\n",
        "    # Análisis de sobreajuste\n",
        "    print(f\"\\n🔍 ANÁLISIS DE SOBREAJUSTE:\")\n",
        "    acc_gap = results['Train (sample)']['accuracy'] - results['Validation']['accuracy']\n",
        "    f1_gap = results['Train (sample)']['f1'] - results['Validation']['f1']\n",
        "\n",
        "    print(f\"   • Accuracy gap (Train-Val): {acc_gap:+.4f}\")\n",
        "    print(f\"   • F1-Score gap (Train-Val): {f1_gap:+.4f}\")\n",
        "\n",
        "    # Consistencia Val-Test\n",
        "    val_test_acc_diff = abs(results['Validation']['accuracy'] - results['Test']['accuracy'])\n",
        "    val_test_f1_diff = abs(results['Validation']['f1'] - results['Test']['f1'])\n",
        "\n",
        "    print(f\"   • Val-Test consistency (Acc): {val_test_acc_diff:.4f}\")\n",
        "    print(f\"   • Val-Test consistency (F1): {val_test_f1_diff:.4f}\")\n",
        "\n",
        "    # Diagnóstico\n",
        "    if acc_gap < 0.15 and f1_gap < 0.15:\n",
        "        print(\"   ✅ SOBREAJUSTE CONTROLADO\")\n",
        "        status = \"GOOD\"\n",
        "    elif acc_gap < 0.25 and f1_gap < 0.25:\n",
        "        print(\"   🟡 SOBREAJUSTE LEVE\")\n",
        "        status = \"MODERATE\"\n",
        "    else:\n",
        "        print(\"   🔴 SOBREAJUSTE AÚN PRESENTE\")\n",
        "        status = \"BAD\"\n",
        "\n",
        "    # Recomendaciones\n",
        "    print(f\"\\n💡 RECOMENDACIONES:\")\n",
        "    if status == \"BAD\":\n",
        "        print(\"   • Cambiar a modelo 'minimal'\")\n",
        "        print(\"   • Aumentar regularización\")\n",
        "        print(\"   • Reducir timesteps aún más\")\n",
        "    elif status == \"MODERATE\":\n",
        "        print(\"   • Monitorear de cerca\")\n",
        "        print(\"   • Considerar ensemble\")\n",
        "    else:\n",
        "        print(\"   • Modelo listo para producción\")\n",
        "        print(\"   • Considerar optimización de umbral\")\n",
        "\n",
        "    return results, status\n",
        "\n",
        "# ---------------------------\n",
        "# EJECUTAR ANÁLISIS\n",
        "# ---------------------------\n",
        "\n",
        "print(\"🔍 Analizando entrenamiento...\")\n",
        "plot_training_analysis(history, f1_callback)\n",
        "\n",
        "print(\"📊 Evaluando rendimiento final...\")\n",
        "results, status = evaluate_final_performance(\n",
        "    model, X_train_final, y_train_final, X_val, y_val, X_test_reshaped, y_test_adj\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# OPTIMIZACIÓN DE UMBRAL (si el modelo es bueno)\n",
        "# ---------------------------\n",
        "\n",
        "#if status in [\"GOOD\", \"MODERATE\"]:\n",
        "#    print(\"\\n🎯 OPTIMIZANDO UMBRAL...\")\n",
        "#\n",
        "#    # Obtener probabilidades\n",
        "#    y_pred_proba_val = model.predict(X_val, verbose=0)\n",
        "#\n",
        "#    # Buscar mejor umbral\n",
        "#    best_f1 = 0\n",
        "#    best_threshold = 0.5\n",
        "#\n",
        "#    for threshold in np.arange(0.2, 0.8, 0.05):\n",
        "#        y_pred_thresh = (y_pred_proba_val >= threshold).astype(int)\n",
        "#        f1_thresh = f1_score(y_val, y_pred_thresh, zero_division=0)\n",
        "#\n",
        "#        if f1_thresh > best_f1:\n",
        "#            best_f1 = f1_thresh\n",
        "#            best_threshold = threshold\n",
        "#\n",
        "#    print(f\"   • Mejor umbral: {best_threshold:.3f}\")\n",
        "#    print(f\"   • F1-Score con umbral óptimo: {best_f1:.4f}\")\n",
        "#\n",
        "#    # Evaluar en test con umbral óptimo\n",
        "#    #y_pred_test_optimal = (model.predict(X_test_reshaped, verbose=0) >= best_threshold).astype(int)\n",
        "#    #test_f1_optimal = f1_score(y_test_adj, y_pred_test_optimal)\n",
        "#\n",
        "#    print(\"📊 Evaluando rendimiento final con UMBRAL OPTIMIZADO...\")\n",
        "#    results, status = evaluate_final_performance(\n",
        "#        model, X_train_final, y_train_final, X_val, y_val, X_test_reshaped, y_test_adj, best_threshold\n",
        "#    )\n",
        "#\n",
        "#    #print(f\"   • F1-Score en test (umbral óptimo): {test_f1_optimal:.4f}\")\n",
        "#\n",
        "print(f\"\\n🎉 PROCESO COMPLETADO\")\n",
        "print(f\"Estado del modelo: {status}\")"
      ],
      "metadata": {
        "id": "Jnt4hczedMaY"
      },
      "id": "Jnt4hczedMaY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# 1️⃣ Obtener predicciones del modelo\n",
        "# -------------------------------\n",
        "y_pred_proba = model.predict(X_test_reshaped, verbose=0)  # Probabilidades\n",
        "y_pred = (y_pred_proba >= best_threshold).astype(int)                # Convertir a 0/1 con umbral 0.5\n",
        "\n",
        "# -------------------------------\n",
        "# 2️⃣ Graficar predicciones vs realidad\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(18,5))\n",
        "\n",
        "plt.plot(y_test_adj, label='Valor Real', marker='o', linestyle='-', alpha=0.7)\n",
        "plt.plot(y_pred, label='Predicción', marker='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.title('Comparación de Predicciones vs Valores Reales (Test Set)')\n",
        "plt.xlabel('Muestra (orden temporal)')\n",
        "plt.ylabel('Clase')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fC6Wpx7ukKbT"
      },
      "id": "fC6Wpx7ukKbT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convertir a array 1D si es necesario\n",
        "y_true = np.array(y_test_adj).flatten()  # ahora es 1D\n",
        "y_pred_proba = model.predict(X_test_reshaped, verbose=0)\n",
        "y_pred = (y_pred_proba >= 0.5).astype(int).flatten()  # también a 1D\n",
        "\n",
        "# Clasificación de los puntos\n",
        "correct_pos = (y_true == 1) & (y_pred == 1)\n",
        "correct_neg = (y_true == 0) & (y_pred == 0)\n",
        "false_pos = (y_true == 0) & (y_pred == 1)\n",
        "false_neg = (y_true == 1) & (y_pred == 0)\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(18,5))\n",
        "plt.scatter(np.where(correct_pos)[0], y_true[correct_pos], color='green', label='Verdadero Positivo', marker='o')\n",
        "plt.scatter(np.where(correct_neg)[0], y_true[correct_neg], color='blue', label='Verdadero Negativo', marker='o')\n",
        "plt.scatter(np.where(false_pos)[0], y_true[false_pos], color='red', label='Falso Positivo', marker='x')\n",
        "plt.scatter(np.where(false_neg)[0], y_true[false_neg], color='orange', label='Falso Negativo', marker='x')\n",
        "\n",
        "plt.title('Desempeño del Modelo en Test Set')\n",
        "plt.xlabel('Muestra (orden temporal)')\n",
        "plt.ylabel('Clase')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "moTd9bGAkdav"
      },
      "id": "moTd9bGAkdav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Walk-Forward en df_bitcoin\n",
        "# =========================================\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.keras import Sequential\n",
        "#from tensorflow.keras.layers import LSTM, GRU, Dense, Conv1D, MaxPooling1D, Dropout\n",
        "#from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "#from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "#from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "#\n",
        "## -----------------------------\n",
        "## Funciones de ventanas (las tuyas)\n",
        "## -----------------------------\n",
        "#def create_windows_multivariate_np(data, window_size, horizon, target_col_idx, shuffle=False):\n",
        "#    if isinstance(data, pd.DataFrame):\n",
        "#        data = data.values\n",
        "#    X, y = [], []\n",
        "#    for i in range(len(data) - window_size - horizon + 1):\n",
        "#        X.append(data[i:i+window_size, :])\n",
        "#        y.append(data[i+window_size+horizon-1, target_col_idx])\n",
        "#    X, y = np.array(X), np.array(y)\n",
        "#    if shuffle:\n",
        "#        indices = np.arange(X.shape[0])\n",
        "#        np.random.shuffle(indices)\n",
        "#        X, y = X[indices], y[indices]\n",
        "#    return X, y\n",
        "#\n",
        "## -----------------------------\n",
        "## Builders de modelos\n",
        "## -----------------------------\n",
        "#def build_lstm(input_shape):\n",
        "#    model = Sequential([\n",
        "#        LSTM(64, input_shape=input_shape),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_gru(input_shape):\n",
        "#    model = Sequential([\n",
        "#        GRU(64, input_shape=input_shape),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_lstm(input_shape):\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        LSTM(64),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_gru(input_shape):\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        GRU(64),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#MODEL_BUILDERS = {\n",
        "#    \"LSTM\": build_lstm,\n",
        "#    \"GRU\": build_gru,\n",
        "#    \"CNN+LSTM\": build_cnn_lstm,\n",
        "#    \"CNN+GRU\": build_cnn_gru\n",
        "#}\n",
        "#\n",
        "## 1. BUILDERS DE MODELOS MEJORADOS\n",
        "#def build_lstm_improved(input_shape):\n",
        "#    \"\"\"LSTM mejorado con mejor arquitectura\"\"\"\n",
        "#    model = Sequential([\n",
        "#        LSTM(128, return_sequences=True, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        LSTM(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_gru_improved(input_shape):\n",
        "#    \"\"\"GRU mejorado con regularización\"\"\"\n",
        "#    model = Sequential([\n",
        "#        GRU(128, return_sequences=True, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        GRU(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_lstm_improved(input_shape):\n",
        "#    \"\"\"CNN+LSTM mejorado con múltiples escalas\"\"\"\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=input_shape),\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        Dropout(0.2),\n",
        "#        LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        LSTM(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "#def build_cnn_gru_improved(input_shape):\n",
        "#    \"\"\"CNN+GRU mejorado\"\"\"\n",
        "#    model = Sequential([\n",
        "#        Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=input_shape),\n",
        "#        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "#        MaxPooling1D(pool_size=2),\n",
        "#        Dropout(0.2),\n",
        "#        GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        GRU(64, dropout=0.2, recurrent_dropout=0.1),\n",
        "#        Dense(64, activation='relu'),\n",
        "#        Dropout(0.3),\n",
        "#        Dense(32, activation='relu'),\n",
        "#        Dropout(0.2),\n",
        "#        Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "#    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "#\n",
        "## Diccionario de modelos\n",
        "#MODEL_BUILDERS_IMPROVED = {\n",
        "#    \"LSTM\": build_lstm_improved,\n",
        "#    \"GRU\": build_gru_improved,\n",
        "#    \"CNN+LSTM\": build_cnn_lstm_improved,\n",
        "#    \"CNN+GRU\": build_cnn_gru_improved\n",
        "#}\n",
        "#\n",
        "#\n",
        "## -----------------------------\n",
        "## Utilidades\n",
        "## -----------------------------\n",
        "#def make_class_weights(y_train):\n",
        "#    classes = np.array([0, 1])\n",
        "#    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "#    return {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "#\n",
        "## -----------------------------\n",
        "## Walk-Forward Validation\n",
        "## -----------------------------\n",
        "#def walk_forward_validation(\n",
        "#    X_values, y_values,\n",
        "#    window_size=30, horizon=1,\n",
        "#    train_size=720, test_size=30, step_size=30,\n",
        "#    build_model_fn=build_lstm,\n",
        "#    epochs=10, batch_size=32, threshold=0.5,\n",
        "#    use_class_weights=True, verbose=0\n",
        "#):\n",
        "#    n = len(X_values)\n",
        "#    n_feat = X_values.shape[1]\n",
        "#\n",
        "#    y_true_all, y_proba_all, y_pred_all, fold_id_all = [], [], [], []\n",
        "#    folds_info = []\n",
        "#\n",
        "#    start = 0\n",
        "#    fold = 0\n",
        "#    while start + train_size + test_size <= n:\n",
        "#        fold += 1\n",
        "#        end_train = start + train_size\n",
        "#        end_test = end_train + test_size\n",
        "#\n",
        "#        segment_X = X_values[start:end_test]\n",
        "#        segment_y = y_values[start:end_test]\n",
        "#\n",
        "#        segment_combined = np.hstack([segment_X, segment_y.reshape(-1, 1)])\n",
        "#        Xw_all, yw_all = create_windows_multivariate_np(\n",
        "#            data=segment_combined,\n",
        "#            window_size=window_size,\n",
        "#            horizon=horizon,\n",
        "#            target_col_idx=segment_combined.shape[1]-1,\n",
        "#            shuffle=False\n",
        "#        )\n",
        "#        Xw_all = Xw_all[:, :, :n_feat]\n",
        "#\n",
        "#        seg_len = len(segment_combined)\n",
        "#        first_target_local = window_size + horizon - 1\n",
        "#        local_target_indices = np.arange(first_target_local, seg_len)\n",
        "#        global_target_indices = start + local_target_indices\n",
        "#\n",
        "#        mask_test = global_target_indices >= end_train\n",
        "#        mask_train = ~mask_test\n",
        "#\n",
        "#        Xw_tr, yw_tr = Xw_all[mask_train], yw_all[mask_train]\n",
        "#        Xw_te, yw_te = Xw_all[mask_test], yw_all[mask_test]\n",
        "#\n",
        "#        scaler = StandardScaler()\n",
        "#        Xw_tr_2d = Xw_tr.reshape(-1, n_feat)\n",
        "#        Xw_te_2d = Xw_te.reshape(-1, n_feat)\n",
        "#        scaler.fit(Xw_tr_2d)\n",
        "#        Xw_tr = scaler.transform(Xw_tr_2d).reshape(Xw_tr.shape[0], window_size, n_feat)\n",
        "#        Xw_te = scaler.transform(Xw_te_2d).reshape(Xw_te.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        class_weight = make_class_weights(yw_tr) if use_class_weights else None\n",
        "#\n",
        "#        model = build_model_fn((window_size, n_feat))\n",
        "#        model.fit(\n",
        "#            Xw_tr, yw_tr,\n",
        "#            epochs=epochs, batch_size=batch_size,\n",
        "#            verbose=verbose,\n",
        "#            class_weight=class_weight,\n",
        "#            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)]\n",
        "#        )\n",
        "#\n",
        "#        proba = model.predict(Xw_te, verbose=0).ravel()\n",
        "#        preds = (proba >= threshold).astype(int)\n",
        "#\n",
        "#        y_true_all.extend(yw_te.tolist())\n",
        "#        y_proba_all.extend(proba.tolist())\n",
        "#        y_pred_all.extend(preds.tolist())\n",
        "#        fold_id_all.extend([fold]*len(yw_te))\n",
        "#\n",
        "#        folds_info.append({\n",
        "#            \"fold\": fold,\n",
        "#            \"train_start\": start,\n",
        "#            \"train_end\": end_train-1,\n",
        "#            \"test_start\": end_train,\n",
        "#            \"test_end\": end_test-1,\n",
        "#            \"n_train_windows\": len(Xw_tr),\n",
        "#            \"n_test_windows\": len(Xw_te),\n",
        "#        })\n",
        "#\n",
        "#        start += step_size\n",
        "#\n",
        "#    y_true_all = np.array(y_true_all)\n",
        "#    y_pred_all = np.array(y_pred_all)\n",
        "#    y_proba_all = np.array(y_proba_all)\n",
        "#\n",
        "#    metrics = {\n",
        "#        \"accuracy\": accuracy_score(y_true_all, y_pred_all),\n",
        "#        \"f1\": f1_score(y_true_all, y_pred_all),\n",
        "#        \"precision\": precision_score(y_true_all, y_pred_all),\n",
        "#        \"recall\": recall_score(y_true_all, y_pred_all),\n",
        "#        \"roc_auc\": roc_auc_score(y_true_all, y_proba_all) if len(np.unique(y_true_all)) == 2 else np.nan\n",
        "#    }\n",
        "#\n",
        "#    preds_df = pd.DataFrame({\n",
        "#        \"y_true\": y_true_all,\n",
        "#        \"y_proba\": y_proba_all,\n",
        "#        \"y_pred\": y_pred_all,\n",
        "#        \"fold\": fold_id_all\n",
        "#    })\n",
        "#\n",
        "#    folds_df = pd.DataFrame(folds_info)\n",
        "#    return metrics, preds_df, folds_df\n",
        "#\n",
        "#def walk_forward_with_threshold_tuning(\n",
        "#    X_values, y_values,\n",
        "#    window_size=30, horizon=1,\n",
        "#    train_size=720, test_size=30, step_size=30,\n",
        "#    build_model_fn=build_lstm,\n",
        "#    epochs=50, batch_size=64,\n",
        "#    val_frac_in_train=0.15,   # fracción del train usada como validation (últos días)\n",
        "#    lr=1e-3,\n",
        "#    use_class_weights=True,\n",
        "#    verbose=0\n",
        "#):\n",
        "#    n = len(X_values)\n",
        "#    n_feat = X_values.shape[1]\n",
        "#\n",
        "#    y_true_all, y_pred_all, y_proba_all = [], [], []\n",
        "#\n",
        "#    start = 0\n",
        "#    fold = 0\n",
        "#    while start + train_size + test_size <= n:\n",
        "#        fold += 1\n",
        "#        end_train = start + train_size\n",
        "#        end_test = end_train + test_size\n",
        "#\n",
        "#        segment_X = X_values[start:end_test]\n",
        "#        segment_y = y_values[start:end_test]\n",
        "#\n",
        "#        segment_combined = np.hstack([segment_X, segment_y.reshape(-1,1)])\n",
        "#        Xw_all, yw_all = create_windows_multivariate_np(\n",
        "#            data=segment_combined, window_size=window_size, horizon=horizon,\n",
        "#            target_col_idx=segment_combined.shape[1]-1, shuffle=False\n",
        "#        )\n",
        "#        Xw_all = Xw_all[:, :, :n_feat]\n",
        "#\n",
        "#        seg_len = len(segment_combined)\n",
        "#        first_target_local = window_size + horizon - 1\n",
        "#        local_target_indices = np.arange(first_target_local, seg_len)\n",
        "#        global_target_indices = start + local_target_indices\n",
        "#\n",
        "#        mask_test = global_target_indices >= end_train\n",
        "#        mask_train = ~mask_test\n",
        "#\n",
        "#        Xw_tr, yw_tr = Xw_all[mask_train], yw_all[mask_train]\n",
        "#        Xw_te, yw_te = Xw_all[mask_test], yw_all[mask_test]\n",
        "#\n",
        "#        # split validation from the END of train (temporal)\n",
        "#        n_tr = len(Xw_tr)\n",
        "#        n_val = int(np.ceil(val_frac_in_train * n_tr))\n",
        "#        n_train_effective = n_tr - n_val\n",
        "#        X_tr_eff, y_tr_eff = Xw_tr[:n_train_effective], yw_tr[:n_train_effective]\n",
        "#        X_val, y_val = Xw_tr[n_train_effective:], yw_tr[n_train_effective:]\n",
        "#\n",
        "#        # scaler fit only on X_tr_eff\n",
        "#        scaler = StandardScaler()\n",
        "#        X_tr_eff_2d = X_tr_eff.reshape(-1, n_feat)\n",
        "#        scaler.fit(X_tr_eff_2d)\n",
        "#        X_tr_eff = scaler.transform(X_tr_eff_2d).reshape(X_tr_eff.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        X_val = scaler.transform(X_val.reshape(-1, n_feat)).reshape(X_val.shape[0], window_size, n_feat)\n",
        "#        Xw_te_scaled = scaler.transform(Xw_te.reshape(-1, n_feat)).reshape(Xw_te.shape[0], window_size, n_feat)\n",
        "#\n",
        "#        class_weight = make_class_weights(y_tr_eff) if use_class_weights else None\n",
        "#\n",
        "#        # Build model and set optimizer lr\n",
        "#        model = build_model_fn((window_size, n_feat))\n",
        "#        # override optimizer lr if using Adam\n",
        "#        try:\n",
        "#            tf.keras.backend.set_value(model.optimizer.lr, lr)\n",
        "#        except Exception:\n",
        "#            pass\n",
        "#\n",
        "#        callbacks = [\n",
        "#            EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=0),\n",
        "#            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0)\n",
        "#        ]\n",
        "#\n",
        "#        model.fit(\n",
        "#            X_tr_eff, y_tr_eff,\n",
        "#            validation_data=(X_val, y_val),\n",
        "#            epochs=epochs, batch_size=batch_size,\n",
        "#            class_weight=class_weight,\n",
        "#            callbacks=callbacks, verbose=verbose\n",
        "#        )\n",
        "#\n",
        "#        # Optimizamos threshold en validation (buscar threshold que maximiza F1)\n",
        "#        val_proba = model.predict(X_val, verbose=0).ravel()\n",
        "#        best_th, best_f1 = 0.5, f1_score(y_val, (val_proba>=0.5).astype(int))\n",
        "#        for th in np.linspace(0.3, 0.7, 41):  # explora 0.30..0.70 cada 0.01\n",
        "#            f1v = f1_score(y_val, (val_proba>=th).astype(int))\n",
        "#            if f1v > best_f1:\n",
        "#                best_f1 = f1v\n",
        "#                best_th = th\n",
        "#\n",
        "#        # predecir test con ese threshold\n",
        "#        proba_test = model.predict(Xw_te_scaled, verbose=0).ravel()\n",
        "#        preds_test = (proba_test >= best_th).astype(int)\n",
        "#\n",
        "#        y_true_all.extend(yw_te.tolist())\n",
        "#        y_proba_all.extend(proba_test.tolist())\n",
        "#        y_pred_all.extend(preds_test.tolist())\n",
        "#\n",
        "#        start += step_size\n",
        "#\n",
        "#    # metrics globales\n",
        "#    from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "#    y_true_all = np.array(y_true_all)\n",
        "#    y_pred_all = np.array(y_pred_all)\n",
        "#    y_proba_all = np.array(y_proba_all)\n",
        "#\n",
        "#    metrics = {\n",
        "#        \"accuracy\": accuracy_score(y_true_all, y_pred_all),\n",
        "#        \"f1\": f1_score(y_true_all, y_pred_all),\n",
        "#        \"precision\": precision_score(y_true_all, y_pred_all),\n",
        "#        \"recall\": recall_score(y_true_all, y_pred_all),\n",
        "#        \"roc_auc\": roc_auc_score(y_true_all, y_proba_all)\n",
        "#    }\n",
        "#    return metrics\n",
        "#\n",
        "## -----------------------------\n",
        "## === EJECUCIÓN SOBRE df_bitcoin ===\n",
        "## -----------------------------\n",
        "## X = todas las columnas menos target\n",
        "#df_bitcoin[\"Open time\"] = pd.to_datetime(df_bitcoin[\"Open time\"])\n",
        "#df_bitcoin = df_bitcoin.set_index(\"Open time\")\n",
        "#\n",
        "#X_values = df_bitcoin.drop(columns=[\"Target\"]).values\n",
        "#y_values = df_bitcoin[\"Target\"].values\n",
        "#\n",
        "#\n",
        "#lookbacks = [14, 30, 60]\n",
        "#horizon = 1\n",
        "#train_size = 720\n",
        "#test_size = 30\n",
        "#step_size = 30\n",
        "#\n",
        "#results = []\n",
        "#\n",
        "#for lb in lookbacks:\n",
        "#    for model_name, builder in MODEL_BUILDERS_IMPROVED.items():\n",
        "#        print(f\"\\n>>> {model_name} | lookback={lb}\")\n",
        "#        metrics = walk_forward_with_threshold_tuning(\n",
        "#            X_values=X_values,\n",
        "#            y_values=y_values,\n",
        "#            window_size=lb,\n",
        "#            horizon=horizon,\n",
        "#            train_size=train_size,\n",
        "#            test_size=test_size,\n",
        "#            step_size=step_size,\n",
        "#            build_model_fn=builder,\n",
        "#            epochs=50,\n",
        "#            batch_size=64,\n",
        "#            val_frac_in_train=0.15,\n",
        "#            lr=1e-3,\n",
        "#            use_class_weights=True,\n",
        "#            verbose=1\n",
        "#        )\n",
        "#        results.append({\"model\": model_name, \"lookback\": lb, **metrics})\n",
        "#\n",
        "#results_df = pd.DataFrame(results).sort_values([\"roc_auc\",\"f1\",\"accuracy\"], ascending=False)\n",
        "#print(\"\\n=== RESULTADOS ===\")\n",
        "#print(results_df)"
      ],
      "metadata": {
        "id": "A0bVqkJ90XQe"
      },
      "id": "A0bVqkJ90XQe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}